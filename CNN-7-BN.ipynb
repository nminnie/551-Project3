{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "I4u4cRvOisni"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o1X9sd13inhf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "import numbers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbAuPVWwX9uZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RRa9O7CMYCfP"
      },
      "cell_type": "markdown",
      "source": [
        "### Go to Drive"
      ]
    },
    {
      "metadata": {
        "id": "jP73mOclIVgp",
        "colab_type": "code",
        "outputId": "caad8ca6-0877-4030-b756-623b4aa1e89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Comp551-Project3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n4x6pKZPoiH1"
      },
      "cell_type": "markdown",
      "source": [
        "### Read Files\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cZah-mbko1eB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = pd.read_pickle('./input/train_images.pkl')\n",
        "X_test = pd.read_pickle('./input/test_images.pkl')\n",
        "Y_train = pd.read_csv('./input/train_labels.csv')\n",
        "Y_train = Y_train['Category'][:].values\n",
        "\n",
        "\n",
        "'''\n",
        "Removing background noise\n",
        "'''\n",
        "for i in range(len(X_train)):\n",
        "    blur = cv2.medianBlur(X_train[i],1)\n",
        "    X_train[i] = cv2.inRange(blur, 230, 255)\n",
        "    \n",
        "for i in range(len(X_test)):\n",
        "    blur = cv2.medianBlur(X_test[i],1)\n",
        "    X_test[i] = cv2.inRange(blur, 230, 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q1k1LZ5SYuKN"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WNMKhlriYynf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_data(Dataset):    \n",
        "    def __init__(self, file_path, \n",
        "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
        "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "                ):\n",
        "        \n",
        "        df = pd.read_pickle(file_path)\n",
        "        \n",
        "        if len(df) == len(X_test):\n",
        "            # test data\n",
        "            self.X = X_test.reshape((-1,64,64)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = None\n",
        "        else:\n",
        "            # training data\n",
        "            self.X = X_train.reshape((-1,64,64)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = Y_train\n",
        "            \n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.transform(self.X[idx]), self.y[idx]\n",
        "        else:\n",
        "            return self.transform(self.X[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nSndy7hRbh-3"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Rotation Transformation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tpAROkmKbbjS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
        "        if isinstance(degrees, numbers.Number):\n",
        "            if degrees < 0:\n",
        "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
        "            self.degrees = (-degrees, degrees)\n",
        "        else:\n",
        "            if len(degrees) != 2:\n",
        "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
        "            self.degrees = degrees\n",
        "\n",
        "        self.resample = resample\n",
        "        self.expand = expand\n",
        "        self.center = center\n",
        "\n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
        "        Returns:\n",
        "            sequence: params to be passed to ``rotate`` for random rotation.\n",
        "        \"\"\"\n",
        "        angle = np.random.uniform(degrees[0], degrees[1])\n",
        "\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
        "            return img.rotate(angle, resample, expand, center)\n",
        "          \n",
        "        angle = self.get_params(self.degrees)\n",
        "\n",
        "        return rotate(img, angle, self.resample, self.expand, self.center)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_R4CBc_icngP"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Vertical and Horizontal Shift"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G9HqMgYJcql9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomShift(object):\n",
        "    def __init__(self, shift):\n",
        "        self.shift = shift\n",
        "        \n",
        "    @staticmethod\n",
        "    def get_params(shift):\n",
        "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
        "\n",
        "        return hshift, vshift \n",
        "    def __call__(self, img):\n",
        "        hshift, vshift = self.get_params(self.shift)\n",
        "        \n",
        "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DCyLcWm3cyLE"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data into Tensors"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9nLvSWeec3TN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataset = MNIST_data('./input/train_images.pkl', transform= transforms.Compose(\n",
        "                            [transforms.ToPILImage(), RandomRotation(degrees=20), RandomShift(3),\n",
        "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
        "test_dataset = MNIST_data('./input/test_images.pkl')\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-Sy72OcuhG3T"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Transformations"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-5Bq-Y5UguBs",
        "outputId": "a0d64102-65bb-4e81-98c0-0158a34cbca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "rotate = RandomRotation(20)\n",
        "shift = RandomShift(3)\n",
        "composed = transforms.Compose([RandomRotation(20),\n",
        "                               RandomShift(3)])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "sample = transforms.ToPILImage()(X_train[65].reshape((64,64)).astype(np.uint8)[:,:,None])\n",
        "for i, tsfrm in enumerate([rotate, shift, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "\n",
        "    ax = plt.subplot(1, 3, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,64)), cmap='gray')    \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAACZCAYAAACG9oW2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jLR9lAZeidTF"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nTJElq39iZCh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "          \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "       \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(64 * 16 * 16, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "          \n",
        "        for m in self.features.children():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "                \n",
        "        for m in self.classifier.children():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "                \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Yvrzpp0witu8",
        "outputId": "91981a9b-e737-4b4c-d1f8-097ad41e57ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6mXl8OTUi0Fo"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ygkR2a-ei1Vd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    optimizer.step()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (batch_idx + 1)% 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                100. * (batch_idx + 1) / len(train_loader), loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VGy_N0mwi8x-"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "21dYFQ7oi8R2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():                   # operations inside don't track history\n",
        "        for data, target in data_loader:\n",
        "            data, target = Variable(data, volatile=True), Variable(target)\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss += F.cross_entropy(output, target, size_average=False)\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(data_loader.dataset)\n",
        "        \n",
        "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        loss, correct, len(data_loader.dataset),\n",
        "        100.0 * float(correct) / len(data_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wvt0TFKWjBy6"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Network"
      ]
    },
    {
      "metadata": {
        "id": "EMPRkkXN8t8i",
        "colab_type": "code",
        "outputId": "40a27275-008a-4228-b90b-ab323913780c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10507
        }
      },
      "cell_type": "code",
      "source": [
        "start_epoch = 0\n",
        "n_epochs = 60\n",
        "\n",
        "model_dir = 'models'\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    train(epoch)\n",
        "    if epoch % 5 == 0:    \n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'epoch-full-{}.pth'.format(epoch)))\n",
        "    torch.cuda.empty_cache()\n",
        "    evaluate(train_loader)\n",
        "    print('Time Elapsed: {}'.format(time.time() - t0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/40000 (16%)]\tLoss: 2.520488\n",
            "Train Epoch: 0 [12800/40000 (32%)]\tLoss: 2.206793\n",
            "Train Epoch: 0 [19200/40000 (48%)]\tLoss: 2.240194\n",
            "Train Epoch: 0 [25600/40000 (64%)]\tLoss: 2.165004\n",
            "Train Epoch: 0 [32000/40000 (80%)]\tLoss: 2.344427\n",
            "Train Epoch: 0 [38400/40000 (96%)]\tLoss: 2.004929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average loss: 2.1748, Accuracy: 11620/40000 (29.050%)\n",
            "\n",
            "Time Elapsed: 86.24834895133972\n",
            "Train Epoch: 1 [6400/40000 (16%)]\tLoss: 1.781172\n",
            "Train Epoch: 1 [12800/40000 (32%)]\tLoss: 1.651523\n",
            "Train Epoch: 1 [19200/40000 (48%)]\tLoss: 1.664386\n",
            "Train Epoch: 1 [25600/40000 (64%)]\tLoss: 1.436850\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 1.572051\n",
            "Train Epoch: 1 [38400/40000 (96%)]\tLoss: 1.395007\n",
            "\n",
            "Average loss: 1.3204, Accuracy: 22049/40000 (55.123%)\n",
            "\n",
            "Time Elapsed: 172.18171858787537\n",
            "Train Epoch: 2 [6400/40000 (16%)]\tLoss: 1.451908\n",
            "Train Epoch: 2 [12800/40000 (32%)]\tLoss: 1.081566\n",
            "Train Epoch: 2 [19200/40000 (48%)]\tLoss: 1.070677\n",
            "Train Epoch: 2 [25600/40000 (64%)]\tLoss: 1.091858\n",
            "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.988671\n",
            "Train Epoch: 2 [38400/40000 (96%)]\tLoss: 1.276494\n",
            "\n",
            "Average loss: 1.4671, Accuracy: 22171/40000 (55.428%)\n",
            "\n",
            "Time Elapsed: 258.18673157691956\n",
            "Train Epoch: 3 [6400/40000 (16%)]\tLoss: 0.920344\n",
            "Train Epoch: 3 [12800/40000 (32%)]\tLoss: 0.816208\n",
            "Train Epoch: 3 [19200/40000 (48%)]\tLoss: 1.089302\n",
            "Train Epoch: 3 [25600/40000 (64%)]\tLoss: 1.211401\n",
            "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 1.049623\n",
            "Train Epoch: 3 [38400/40000 (96%)]\tLoss: 1.220246\n",
            "\n",
            "Average loss: 0.8786, Accuracy: 28522/40000 (71.305%)\n",
            "\n",
            "Time Elapsed: 343.86160230636597\n",
            "Train Epoch: 4 [6400/40000 (16%)]\tLoss: 1.052233\n",
            "Train Epoch: 4 [12800/40000 (32%)]\tLoss: 1.357661\n",
            "Train Epoch: 4 [19200/40000 (48%)]\tLoss: 1.064600\n",
            "Train Epoch: 4 [25600/40000 (64%)]\tLoss: 1.114434\n",
            "Train Epoch: 4 [32000/40000 (80%)]\tLoss: 0.886925\n",
            "Train Epoch: 4 [38400/40000 (96%)]\tLoss: 1.095636\n",
            "\n",
            "Average loss: 0.8240, Accuracy: 29595/40000 (73.987%)\n",
            "\n",
            "Time Elapsed: 429.8776729106903\n",
            "Train Epoch: 5 [6400/40000 (16%)]\tLoss: 0.818787\n",
            "Train Epoch: 5 [12800/40000 (32%)]\tLoss: 1.088365\n",
            "Train Epoch: 5 [19200/40000 (48%)]\tLoss: 0.973190\n",
            "Train Epoch: 5 [25600/40000 (64%)]\tLoss: 0.863300\n",
            "Train Epoch: 5 [32000/40000 (80%)]\tLoss: 0.907191\n",
            "Train Epoch: 5 [38400/40000 (96%)]\tLoss: 0.618998\n",
            "\n",
            "Average loss: 0.5974, Accuracy: 32711/40000 (81.778%)\n",
            "\n",
            "Time Elapsed: 517.4757032394409\n",
            "Train Epoch: 6 [6400/40000 (16%)]\tLoss: 0.806255\n",
            "Train Epoch: 6 [12800/40000 (32%)]\tLoss: 0.704121\n",
            "Train Epoch: 6 [19200/40000 (48%)]\tLoss: 0.906399\n",
            "Train Epoch: 6 [25600/40000 (64%)]\tLoss: 0.834149\n",
            "Train Epoch: 6 [32000/40000 (80%)]\tLoss: 0.587407\n",
            "Train Epoch: 6 [38400/40000 (96%)]\tLoss: 0.939545\n",
            "\n",
            "Average loss: 0.6839, Accuracy: 31248/40000 (78.120%)\n",
            "\n",
            "Time Elapsed: 603.0800399780273\n",
            "Train Epoch: 7 [6400/40000 (16%)]\tLoss: 0.909608\n",
            "Train Epoch: 7 [12800/40000 (32%)]\tLoss: 0.845612\n",
            "Train Epoch: 7 [19200/40000 (48%)]\tLoss: 0.504915\n",
            "Train Epoch: 7 [25600/40000 (64%)]\tLoss: 1.016790\n",
            "Train Epoch: 7 [32000/40000 (80%)]\tLoss: 0.793494\n",
            "Train Epoch: 7 [38400/40000 (96%)]\tLoss: 0.835188\n",
            "\n",
            "Average loss: 0.5239, Accuracy: 33333/40000 (83.332%)\n",
            "\n",
            "Time Elapsed: 688.8655877113342\n",
            "Train Epoch: 8 [6400/40000 (16%)]\tLoss: 0.680291\n",
            "Train Epoch: 8 [12800/40000 (32%)]\tLoss: 0.614452\n",
            "Train Epoch: 8 [19200/40000 (48%)]\tLoss: 0.996305\n",
            "Train Epoch: 8 [25600/40000 (64%)]\tLoss: 0.693302\n",
            "Train Epoch: 8 [32000/40000 (80%)]\tLoss: 0.603264\n",
            "Train Epoch: 8 [38400/40000 (96%)]\tLoss: 0.714921\n",
            "\n",
            "Average loss: 0.5157, Accuracy: 33579/40000 (83.948%)\n",
            "\n",
            "Time Elapsed: 774.8292422294617\n",
            "Train Epoch: 9 [6400/40000 (16%)]\tLoss: 0.955785\n",
            "Train Epoch: 9 [12800/40000 (32%)]\tLoss: 0.930304\n",
            "Train Epoch: 9 [19200/40000 (48%)]\tLoss: 0.972502\n",
            "Train Epoch: 9 [25600/40000 (64%)]\tLoss: 0.815588\n",
            "Train Epoch: 9 [32000/40000 (80%)]\tLoss: 0.641395\n",
            "Train Epoch: 9 [38400/40000 (96%)]\tLoss: 0.672439\n",
            "\n",
            "Average loss: 0.8404, Accuracy: 30703/40000 (76.757%)\n",
            "\n",
            "Time Elapsed: 860.5107529163361\n",
            "Train Epoch: 10 [6400/40000 (16%)]\tLoss: 0.654271\n",
            "Train Epoch: 10 [12800/40000 (32%)]\tLoss: 0.554043\n",
            "Train Epoch: 10 [19200/40000 (48%)]\tLoss: 0.583051\n",
            "Train Epoch: 10 [25600/40000 (64%)]\tLoss: 0.670814\n",
            "Train Epoch: 10 [32000/40000 (80%)]\tLoss: 0.878786\n",
            "Train Epoch: 10 [38400/40000 (96%)]\tLoss: 0.733487\n",
            "\n",
            "Average loss: 0.4691, Accuracy: 34084/40000 (85.210%)\n",
            "\n",
            "Time Elapsed: 948.4999129772186\n",
            "Train Epoch: 11 [6400/40000 (16%)]\tLoss: 0.765877\n",
            "Train Epoch: 11 [12800/40000 (32%)]\tLoss: 0.746945\n",
            "Train Epoch: 11 [19200/40000 (48%)]\tLoss: 0.363625\n",
            "Train Epoch: 11 [25600/40000 (64%)]\tLoss: 0.656004\n",
            "Train Epoch: 11 [32000/40000 (80%)]\tLoss: 0.851281\n",
            "Train Epoch: 11 [38400/40000 (96%)]\tLoss: 0.640277\n",
            "\n",
            "Average loss: 0.6178, Accuracy: 32913/40000 (82.282%)\n",
            "\n",
            "Time Elapsed: 1034.3473479747772\n",
            "Train Epoch: 12 [6400/40000 (16%)]\tLoss: 0.639068\n",
            "Train Epoch: 12 [12800/40000 (32%)]\tLoss: 0.554440\n",
            "Train Epoch: 12 [19200/40000 (48%)]\tLoss: 0.497443\n",
            "Train Epoch: 12 [25600/40000 (64%)]\tLoss: 0.419896\n",
            "Train Epoch: 12 [32000/40000 (80%)]\tLoss: 0.572332\n",
            "Train Epoch: 12 [38400/40000 (96%)]\tLoss: 0.594765\n",
            "\n",
            "Average loss: 0.3601, Accuracy: 35471/40000 (88.677%)\n",
            "\n",
            "Time Elapsed: 1120.0841512680054\n",
            "Train Epoch: 13 [6400/40000 (16%)]\tLoss: 0.719734\n",
            "Train Epoch: 13 [12800/40000 (32%)]\tLoss: 0.676805\n",
            "Train Epoch: 13 [19200/40000 (48%)]\tLoss: 0.754174\n",
            "Train Epoch: 13 [25600/40000 (64%)]\tLoss: 0.688593\n",
            "Train Epoch: 13 [32000/40000 (80%)]\tLoss: 0.395189\n",
            "Train Epoch: 13 [38400/40000 (96%)]\tLoss: 0.749195\n",
            "\n",
            "Average loss: 0.3919, Accuracy: 35343/40000 (88.358%)\n",
            "\n",
            "Time Elapsed: 1205.8869440555573\n",
            "Train Epoch: 14 [6400/40000 (16%)]\tLoss: 0.602678\n",
            "Train Epoch: 14 [12800/40000 (32%)]\tLoss: 0.737241\n",
            "Train Epoch: 14 [19200/40000 (48%)]\tLoss: 0.670812\n",
            "Train Epoch: 14 [25600/40000 (64%)]\tLoss: 0.654211\n",
            "Train Epoch: 14 [32000/40000 (80%)]\tLoss: 0.739193\n",
            "Train Epoch: 14 [38400/40000 (96%)]\tLoss: 0.567500\n",
            "\n",
            "Average loss: 0.3659, Accuracy: 35480/40000 (88.700%)\n",
            "\n",
            "Time Elapsed: 1291.7317025661469\n",
            "Train Epoch: 15 [6400/40000 (16%)]\tLoss: 0.616247\n",
            "Train Epoch: 15 [12800/40000 (32%)]\tLoss: 0.762601\n",
            "Train Epoch: 15 [19200/40000 (48%)]\tLoss: 0.959380\n",
            "Train Epoch: 15 [25600/40000 (64%)]\tLoss: 0.656277\n",
            "Train Epoch: 15 [32000/40000 (80%)]\tLoss: 0.571857\n",
            "Train Epoch: 15 [38400/40000 (96%)]\tLoss: 0.348534\n",
            "\n",
            "Average loss: 0.3819, Accuracy: 35418/40000 (88.545%)\n",
            "\n",
            "Time Elapsed: 1379.0551524162292\n",
            "Train Epoch: 16 [6400/40000 (16%)]\tLoss: 0.557324\n",
            "Train Epoch: 16 [12800/40000 (32%)]\tLoss: 0.888469\n",
            "Train Epoch: 16 [19200/40000 (48%)]\tLoss: 0.413011\n",
            "Train Epoch: 16 [25600/40000 (64%)]\tLoss: 0.732633\n",
            "Train Epoch: 16 [32000/40000 (80%)]\tLoss: 0.967584\n",
            "Train Epoch: 16 [38400/40000 (96%)]\tLoss: 0.783854\n",
            "\n",
            "Average loss: 0.3823, Accuracy: 35300/40000 (88.250%)\n",
            "\n",
            "Time Elapsed: 1464.9502108097076\n",
            "Train Epoch: 17 [6400/40000 (16%)]\tLoss: 0.410361\n",
            "Train Epoch: 17 [12800/40000 (32%)]\tLoss: 0.562673\n",
            "Train Epoch: 17 [19200/40000 (48%)]\tLoss: 0.614202\n",
            "Train Epoch: 17 [25600/40000 (64%)]\tLoss: 0.581402\n",
            "Train Epoch: 17 [32000/40000 (80%)]\tLoss: 0.753763\n",
            "Train Epoch: 17 [38400/40000 (96%)]\tLoss: 0.592574\n",
            "\n",
            "Average loss: 0.3333, Accuracy: 35834/40000 (89.585%)\n",
            "\n",
            "Time Elapsed: 1550.504165172577\n",
            "Train Epoch: 18 [6400/40000 (16%)]\tLoss: 0.486127\n",
            "Train Epoch: 18 [12800/40000 (32%)]\tLoss: 0.586730\n",
            "Train Epoch: 18 [19200/40000 (48%)]\tLoss: 0.630261\n",
            "Train Epoch: 18 [25600/40000 (64%)]\tLoss: 0.658610\n",
            "Train Epoch: 18 [32000/40000 (80%)]\tLoss: 0.532666\n",
            "Train Epoch: 18 [38400/40000 (96%)]\tLoss: 0.540110\n",
            "\n",
            "Average loss: 0.3156, Accuracy: 36177/40000 (90.442%)\n",
            "\n",
            "Time Elapsed: 1635.9357280731201\n",
            "Train Epoch: 19 [6400/40000 (16%)]\tLoss: 0.660910\n",
            "Train Epoch: 19 [12800/40000 (32%)]\tLoss: 0.615696\n",
            "Train Epoch: 19 [19200/40000 (48%)]\tLoss: 0.612548\n",
            "Train Epoch: 19 [25600/40000 (64%)]\tLoss: 0.375240\n",
            "Train Epoch: 19 [32000/40000 (80%)]\tLoss: 0.679137\n",
            "Train Epoch: 19 [38400/40000 (96%)]\tLoss: 0.751574\n",
            "\n",
            "Average loss: 0.3195, Accuracy: 36405/40000 (91.013%)\n",
            "\n",
            "Time Elapsed: 1721.581821680069\n",
            "Train Epoch: 20 [6400/40000 (16%)]\tLoss: 0.617425\n",
            "Train Epoch: 20 [12800/40000 (32%)]\tLoss: 0.629988\n",
            "Train Epoch: 20 [19200/40000 (48%)]\tLoss: 0.419629\n",
            "Train Epoch: 20 [25600/40000 (64%)]\tLoss: 0.361222\n",
            "Train Epoch: 20 [32000/40000 (80%)]\tLoss: 0.392344\n",
            "Train Epoch: 20 [38400/40000 (96%)]\tLoss: 1.155782\n",
            "\n",
            "Average loss: 0.3370, Accuracy: 35896/40000 (89.740%)\n",
            "\n",
            "Time Elapsed: 1808.7466447353363\n",
            "Train Epoch: 21 [6400/40000 (16%)]\tLoss: 0.588995\n",
            "Train Epoch: 21 [12800/40000 (32%)]\tLoss: 0.637129\n",
            "Train Epoch: 21 [19200/40000 (48%)]\tLoss: 0.504261\n",
            "Train Epoch: 21 [25600/40000 (64%)]\tLoss: 0.389699\n",
            "Train Epoch: 21 [32000/40000 (80%)]\tLoss: 0.716807\n",
            "Train Epoch: 21 [38400/40000 (96%)]\tLoss: 0.485292\n",
            "\n",
            "Average loss: 0.3098, Accuracy: 36275/40000 (90.688%)\n",
            "\n",
            "Time Elapsed: 1894.4726741313934\n",
            "Train Epoch: 22 [6400/40000 (16%)]\tLoss: 0.427602\n",
            "Train Epoch: 22 [12800/40000 (32%)]\tLoss: 0.328135\n",
            "Train Epoch: 22 [19200/40000 (48%)]\tLoss: 0.446115\n",
            "Train Epoch: 22 [25600/40000 (64%)]\tLoss: 0.577259\n",
            "Train Epoch: 22 [32000/40000 (80%)]\tLoss: 0.526024\n",
            "Train Epoch: 22 [38400/40000 (96%)]\tLoss: 0.501481\n",
            "\n",
            "Average loss: 0.2991, Accuracy: 36533/40000 (91.332%)\n",
            "\n",
            "Time Elapsed: 1980.1006472110748\n",
            "Train Epoch: 23 [6400/40000 (16%)]\tLoss: 0.644921\n",
            "Train Epoch: 23 [12800/40000 (32%)]\tLoss: 0.465120\n",
            "Train Epoch: 23 [19200/40000 (48%)]\tLoss: 0.775493\n",
            "Train Epoch: 23 [25600/40000 (64%)]\tLoss: 0.443191\n",
            "Train Epoch: 23 [32000/40000 (80%)]\tLoss: 0.401810\n",
            "Train Epoch: 23 [38400/40000 (96%)]\tLoss: 0.445359\n",
            "\n",
            "Average loss: 0.3610, Accuracy: 36138/40000 (90.345%)\n",
            "\n",
            "Time Elapsed: 2065.683401107788\n",
            "Train Epoch: 24 [6400/40000 (16%)]\tLoss: 0.532875\n",
            "Train Epoch: 24 [12800/40000 (32%)]\tLoss: 0.413474\n",
            "Train Epoch: 24 [19200/40000 (48%)]\tLoss: 0.527516\n",
            "Train Epoch: 24 [25600/40000 (64%)]\tLoss: 0.496852\n",
            "Train Epoch: 24 [32000/40000 (80%)]\tLoss: 0.363136\n",
            "Train Epoch: 24 [38400/40000 (96%)]\tLoss: 0.756126\n",
            "\n",
            "Average loss: 0.2996, Accuracy: 36271/40000 (90.677%)\n",
            "\n",
            "Time Elapsed: 2151.2953305244446\n",
            "Train Epoch: 25 [6400/40000 (16%)]\tLoss: 0.386870\n",
            "Train Epoch: 25 [12800/40000 (32%)]\tLoss: 0.574668\n",
            "Train Epoch: 25 [19200/40000 (48%)]\tLoss: 0.454946\n",
            "Train Epoch: 25 [25600/40000 (64%)]\tLoss: 0.554101\n",
            "Train Epoch: 25 [32000/40000 (80%)]\tLoss: 0.542760\n",
            "Train Epoch: 25 [38400/40000 (96%)]\tLoss: 0.359805\n",
            "\n",
            "Average loss: 0.2598, Accuracy: 36850/40000 (92.125%)\n",
            "\n",
            "Time Elapsed: 2238.5350620746613\n",
            "Train Epoch: 26 [6400/40000 (16%)]\tLoss: 0.575751\n",
            "Train Epoch: 26 [12800/40000 (32%)]\tLoss: 0.372502\n",
            "Train Epoch: 26 [19200/40000 (48%)]\tLoss: 0.515380\n",
            "Train Epoch: 26 [25600/40000 (64%)]\tLoss: 0.475226\n",
            "Train Epoch: 26 [32000/40000 (80%)]\tLoss: 0.513168\n",
            "Train Epoch: 26 [38400/40000 (96%)]\tLoss: 0.593348\n",
            "\n",
            "Average loss: 0.2778, Accuracy: 36427/40000 (91.067%)\n",
            "\n",
            "Time Elapsed: 2324.011293411255\n",
            "Train Epoch: 27 [6400/40000 (16%)]\tLoss: 0.556630\n",
            "Train Epoch: 27 [12800/40000 (32%)]\tLoss: 0.526382\n",
            "Train Epoch: 27 [19200/40000 (48%)]\tLoss: 0.346450\n",
            "Train Epoch: 27 [25600/40000 (64%)]\tLoss: 0.685068\n",
            "Train Epoch: 27 [32000/40000 (80%)]\tLoss: 0.204524\n",
            "Train Epoch: 27 [38400/40000 (96%)]\tLoss: 0.506563\n",
            "\n",
            "Average loss: 0.2686, Accuracy: 36670/40000 (91.675%)\n",
            "\n",
            "Time Elapsed: 2409.4679675102234\n",
            "Train Epoch: 28 [6400/40000 (16%)]\tLoss: 0.329667\n",
            "Train Epoch: 28 [12800/40000 (32%)]\tLoss: 0.374683\n",
            "Train Epoch: 28 [19200/40000 (48%)]\tLoss: 0.640230\n",
            "Train Epoch: 28 [25600/40000 (64%)]\tLoss: 0.396612\n",
            "Train Epoch: 28 [32000/40000 (80%)]\tLoss: 0.317274\n",
            "Train Epoch: 28 [38400/40000 (96%)]\tLoss: 0.532001\n",
            "\n",
            "Average loss: 0.2567, Accuracy: 36811/40000 (92.028%)\n",
            "\n",
            "Time Elapsed: 2494.9030351638794\n",
            "Train Epoch: 29 [6400/40000 (16%)]\tLoss: 0.779652\n",
            "Train Epoch: 29 [12800/40000 (32%)]\tLoss: 0.450396\n",
            "Train Epoch: 29 [19200/40000 (48%)]\tLoss: 0.669716\n",
            "Train Epoch: 29 [25600/40000 (64%)]\tLoss: 0.673396\n",
            "Train Epoch: 29 [32000/40000 (80%)]\tLoss: 0.453694\n",
            "Train Epoch: 29 [38400/40000 (96%)]\tLoss: 0.508743\n",
            "\n",
            "Average loss: 0.2986, Accuracy: 36450/40000 (91.125%)\n",
            "\n",
            "Time Elapsed: 2580.2486493587494\n",
            "Train Epoch: 30 [6400/40000 (16%)]\tLoss: 0.483378\n",
            "Train Epoch: 30 [12800/40000 (32%)]\tLoss: 0.481038\n",
            "Train Epoch: 30 [19200/40000 (48%)]\tLoss: 0.365985\n",
            "Train Epoch: 30 [25600/40000 (64%)]\tLoss: 0.309191\n",
            "Train Epoch: 30 [32000/40000 (80%)]\tLoss: 0.609941\n",
            "Train Epoch: 30 [38400/40000 (96%)]\tLoss: 0.413105\n",
            "\n",
            "Average loss: 0.2689, Accuracy: 36779/40000 (91.948%)\n",
            "\n",
            "Time Elapsed: 2667.354717731476\n",
            "Train Epoch: 31 [6400/40000 (16%)]\tLoss: 0.503904\n",
            "Train Epoch: 31 [12800/40000 (32%)]\tLoss: 0.397495\n",
            "Train Epoch: 31 [19200/40000 (48%)]\tLoss: 0.594240\n",
            "Train Epoch: 31 [25600/40000 (64%)]\tLoss: 0.662076\n",
            "Train Epoch: 31 [32000/40000 (80%)]\tLoss: 0.347252\n",
            "Train Epoch: 31 [38400/40000 (96%)]\tLoss: 0.436532\n",
            "\n",
            "Average loss: 0.2376, Accuracy: 37189/40000 (92.972%)\n",
            "\n",
            "Time Elapsed: 2752.3331611156464\n",
            "Train Epoch: 32 [6400/40000 (16%)]\tLoss: 0.289345\n",
            "Train Epoch: 32 [12800/40000 (32%)]\tLoss: 0.708543\n",
            "Train Epoch: 32 [19200/40000 (48%)]\tLoss: 0.660802\n",
            "Train Epoch: 32 [25600/40000 (64%)]\tLoss: 0.351592\n",
            "Train Epoch: 32 [32000/40000 (80%)]\tLoss: 0.416216\n",
            "Train Epoch: 32 [38400/40000 (96%)]\tLoss: 0.449184\n",
            "\n",
            "Average loss: 0.2540, Accuracy: 37051/40000 (92.627%)\n",
            "\n",
            "Time Elapsed: 2837.566855430603\n",
            "Train Epoch: 33 [6400/40000 (16%)]\tLoss: 0.411380\n",
            "Train Epoch: 33 [12800/40000 (32%)]\tLoss: 0.216866\n",
            "Train Epoch: 33 [19200/40000 (48%)]\tLoss: 0.265854\n",
            "Train Epoch: 33 [25600/40000 (64%)]\tLoss: 0.229078\n",
            "Train Epoch: 33 [32000/40000 (80%)]\tLoss: 0.326391\n",
            "Train Epoch: 33 [38400/40000 (96%)]\tLoss: 0.389713\n",
            "\n",
            "Average loss: 0.2899, Accuracy: 36961/40000 (92.403%)\n",
            "\n",
            "Time Elapsed: 2923.01877117157\n",
            "Train Epoch: 34 [6400/40000 (16%)]\tLoss: 0.268882\n",
            "Train Epoch: 34 [12800/40000 (32%)]\tLoss: 0.317701\n",
            "Train Epoch: 34 [19200/40000 (48%)]\tLoss: 0.325837\n",
            "Train Epoch: 34 [25600/40000 (64%)]\tLoss: 0.319822\n",
            "Train Epoch: 34 [32000/40000 (80%)]\tLoss: 0.329326\n",
            "Train Epoch: 34 [38400/40000 (96%)]\tLoss: 0.317164\n",
            "\n",
            "Average loss: 0.2488, Accuracy: 37044/40000 (92.610%)\n",
            "\n",
            "Time Elapsed: 3008.184615135193\n",
            "Train Epoch: 35 [6400/40000 (16%)]\tLoss: 0.514856\n",
            "Train Epoch: 35 [12800/40000 (32%)]\tLoss: 0.626026\n",
            "Train Epoch: 35 [19200/40000 (48%)]\tLoss: 0.573806\n",
            "Train Epoch: 35 [25600/40000 (64%)]\tLoss: 0.249067\n",
            "Train Epoch: 35 [32000/40000 (80%)]\tLoss: 0.483094\n",
            "Train Epoch: 35 [38400/40000 (96%)]\tLoss: 0.429657\n",
            "\n",
            "Average loss: 0.2172, Accuracy: 37284/40000 (93.210%)\n",
            "\n",
            "Time Elapsed: 3095.5805835723877\n",
            "Train Epoch: 36 [6400/40000 (16%)]\tLoss: 0.465458\n",
            "Train Epoch: 36 [12800/40000 (32%)]\tLoss: 0.304807\n",
            "Train Epoch: 36 [19200/40000 (48%)]\tLoss: 0.265498\n",
            "Train Epoch: 36 [25600/40000 (64%)]\tLoss: 0.353524\n",
            "Train Epoch: 36 [32000/40000 (80%)]\tLoss: 0.325238\n",
            "Train Epoch: 36 [38400/40000 (96%)]\tLoss: 0.690748\n",
            "\n",
            "Average loss: 0.2662, Accuracy: 36717/40000 (91.793%)\n",
            "\n",
            "Time Elapsed: 3180.964535474777\n",
            "Train Epoch: 37 [6400/40000 (16%)]\tLoss: 0.168493\n",
            "Train Epoch: 37 [12800/40000 (32%)]\tLoss: 0.786709\n",
            "Train Epoch: 37 [19200/40000 (48%)]\tLoss: 0.313186\n",
            "Train Epoch: 37 [25600/40000 (64%)]\tLoss: 0.250984\n",
            "Train Epoch: 37 [32000/40000 (80%)]\tLoss: 0.250976\n",
            "Train Epoch: 37 [38400/40000 (96%)]\tLoss: 0.399983\n",
            "\n",
            "Average loss: 0.3452, Accuracy: 36333/40000 (90.832%)\n",
            "\n",
            "Time Elapsed: 3266.2493941783905\n",
            "Train Epoch: 38 [6400/40000 (16%)]\tLoss: 0.368258\n",
            "Train Epoch: 38 [12800/40000 (32%)]\tLoss: 0.830069\n",
            "Train Epoch: 38 [19200/40000 (48%)]\tLoss: 0.430241\n",
            "Train Epoch: 38 [25600/40000 (64%)]\tLoss: 0.474710\n",
            "Train Epoch: 38 [32000/40000 (80%)]\tLoss: 0.451039\n",
            "Train Epoch: 38 [38400/40000 (96%)]\tLoss: 0.266430\n",
            "\n",
            "Average loss: 0.2304, Accuracy: 37260/40000 (93.150%)\n",
            "\n",
            "Time Elapsed: 3351.686799764633\n",
            "Train Epoch: 39 [6400/40000 (16%)]\tLoss: 0.507371\n",
            "Train Epoch: 39 [12800/40000 (32%)]\tLoss: 0.264081\n",
            "Train Epoch: 39 [19200/40000 (48%)]\tLoss: 0.566972\n",
            "Train Epoch: 39 [25600/40000 (64%)]\tLoss: 0.332790\n",
            "Train Epoch: 39 [32000/40000 (80%)]\tLoss: 0.709578\n",
            "Train Epoch: 39 [38400/40000 (96%)]\tLoss: 0.531429\n",
            "\n",
            "Average loss: 0.2252, Accuracy: 37315/40000 (93.287%)\n",
            "\n",
            "Time Elapsed: 3436.9142491817474\n",
            "Train Epoch: 40 [6400/40000 (16%)]\tLoss: 0.401232\n",
            "Train Epoch: 40 [12800/40000 (32%)]\tLoss: 0.363209\n",
            "Train Epoch: 40 [19200/40000 (48%)]\tLoss: 0.426190\n",
            "Train Epoch: 40 [25600/40000 (64%)]\tLoss: 0.233659\n",
            "Train Epoch: 40 [32000/40000 (80%)]\tLoss: 0.385408\n",
            "Train Epoch: 40 [38400/40000 (96%)]\tLoss: 0.272479\n",
            "\n",
            "Average loss: 0.2206, Accuracy: 37430/40000 (93.575%)\n",
            "\n",
            "Time Elapsed: 3524.007729291916\n",
            "Train Epoch: 41 [6400/40000 (16%)]\tLoss: 0.165939\n",
            "Train Epoch: 41 [12800/40000 (32%)]\tLoss: 0.309075\n",
            "Train Epoch: 41 [19200/40000 (48%)]\tLoss: 0.462622\n",
            "Train Epoch: 41 [25600/40000 (64%)]\tLoss: 0.273779\n",
            "Train Epoch: 41 [32000/40000 (80%)]\tLoss: 0.438997\n",
            "Train Epoch: 41 [38400/40000 (96%)]\tLoss: 0.646551\n",
            "\n",
            "Average loss: 0.2031, Accuracy: 37568/40000 (93.920%)\n",
            "\n",
            "Time Elapsed: 3609.2248401641846\n",
            "Train Epoch: 42 [6400/40000 (16%)]\tLoss: 0.552370\n",
            "Train Epoch: 42 [12800/40000 (32%)]\tLoss: 0.625968\n",
            "Train Epoch: 42 [19200/40000 (48%)]\tLoss: 0.241255\n",
            "Train Epoch: 42 [25600/40000 (64%)]\tLoss: 0.332100\n",
            "Train Epoch: 42 [32000/40000 (80%)]\tLoss: 0.621978\n",
            "Train Epoch: 42 [38400/40000 (96%)]\tLoss: 0.299327\n",
            "\n",
            "Average loss: 0.2187, Accuracy: 37437/40000 (93.593%)\n",
            "\n",
            "Time Elapsed: 3695.052838563919\n",
            "Train Epoch: 43 [6400/40000 (16%)]\tLoss: 0.287699\n",
            "Train Epoch: 43 [12800/40000 (32%)]\tLoss: 0.399644\n",
            "Train Epoch: 43 [19200/40000 (48%)]\tLoss: 0.338427\n",
            "Train Epoch: 43 [25600/40000 (64%)]\tLoss: 0.401174\n",
            "Train Epoch: 43 [32000/40000 (80%)]\tLoss: 0.224315\n",
            "Train Epoch: 43 [38400/40000 (96%)]\tLoss: 0.247909\n",
            "\n",
            "Average loss: 0.1989, Accuracy: 37561/40000 (93.903%)\n",
            "\n",
            "Time Elapsed: 3780.1569805145264\n",
            "Train Epoch: 44 [6400/40000 (16%)]\tLoss: 0.274582\n",
            "Train Epoch: 44 [12800/40000 (32%)]\tLoss: 0.196617\n",
            "Train Epoch: 44 [19200/40000 (48%)]\tLoss: 0.481096\n",
            "Train Epoch: 44 [25600/40000 (64%)]\tLoss: 0.269942\n",
            "Train Epoch: 44 [32000/40000 (80%)]\tLoss: 0.323137\n",
            "Train Epoch: 44 [38400/40000 (96%)]\tLoss: 0.469205\n",
            "\n",
            "Average loss: 0.2358, Accuracy: 37378/40000 (93.445%)\n",
            "\n",
            "Time Elapsed: 3865.2268030643463\n",
            "Train Epoch: 45 [6400/40000 (16%)]\tLoss: 0.247399\n",
            "Train Epoch: 45 [12800/40000 (32%)]\tLoss: 0.263314\n",
            "Train Epoch: 45 [19200/40000 (48%)]\tLoss: 0.255063\n",
            "Train Epoch: 45 [25600/40000 (64%)]\tLoss: 0.801210\n",
            "Train Epoch: 45 [32000/40000 (80%)]\tLoss: 0.239716\n",
            "Train Epoch: 45 [38400/40000 (96%)]\tLoss: 0.269751\n",
            "\n",
            "Average loss: 0.2010, Accuracy: 37443/40000 (93.608%)\n",
            "\n",
            "Time Elapsed: 3952.1655597686768\n",
            "Train Epoch: 46 [6400/40000 (16%)]\tLoss: 0.500769\n",
            "Train Epoch: 46 [12800/40000 (32%)]\tLoss: 0.345926\n",
            "Train Epoch: 46 [19200/40000 (48%)]\tLoss: 0.471571\n",
            "Train Epoch: 46 [25600/40000 (64%)]\tLoss: 0.463714\n",
            "Train Epoch: 46 [32000/40000 (80%)]\tLoss: 0.472476\n",
            "Train Epoch: 46 [38400/40000 (96%)]\tLoss: 0.626890\n",
            "\n",
            "Average loss: 0.2309, Accuracy: 37189/40000 (92.972%)\n",
            "\n",
            "Time Elapsed: 4038.165590763092\n",
            "Train Epoch: 47 [6400/40000 (16%)]\tLoss: 0.343567\n",
            "Train Epoch: 47 [12800/40000 (32%)]\tLoss: 0.566674\n",
            "Train Epoch: 47 [19200/40000 (48%)]\tLoss: 0.171256\n",
            "Train Epoch: 47 [25600/40000 (64%)]\tLoss: 0.452559\n",
            "Train Epoch: 47 [32000/40000 (80%)]\tLoss: 0.489297\n",
            "Train Epoch: 47 [38400/40000 (96%)]\tLoss: 0.319396\n",
            "\n",
            "Average loss: 0.1931, Accuracy: 37738/40000 (94.345%)\n",
            "\n",
            "Time Elapsed: 4123.464804172516\n",
            "Train Epoch: 48 [6400/40000 (16%)]\tLoss: 0.508367\n",
            "Train Epoch: 48 [12800/40000 (32%)]\tLoss: 0.365651\n",
            "Train Epoch: 48 [19200/40000 (48%)]\tLoss: 0.459250\n",
            "Train Epoch: 48 [25600/40000 (64%)]\tLoss: 0.509917\n",
            "Train Epoch: 48 [32000/40000 (80%)]\tLoss: 0.342779\n",
            "Train Epoch: 48 [38400/40000 (96%)]\tLoss: 0.303137\n",
            "\n",
            "Average loss: 0.1911, Accuracy: 37701/40000 (94.252%)\n",
            "\n",
            "Time Elapsed: 4208.890695333481\n",
            "Train Epoch: 49 [6400/40000 (16%)]\tLoss: 0.455186\n",
            "Train Epoch: 49 [12800/40000 (32%)]\tLoss: 0.562692\n",
            "Train Epoch: 49 [19200/40000 (48%)]\tLoss: 0.338288\n",
            "Train Epoch: 49 [25600/40000 (64%)]\tLoss: 0.352013\n",
            "Train Epoch: 49 [32000/40000 (80%)]\tLoss: 0.147308\n",
            "Train Epoch: 49 [38400/40000 (96%)]\tLoss: 0.379716\n",
            "\n",
            "Average loss: 0.2282, Accuracy: 37107/40000 (92.767%)\n",
            "\n",
            "Time Elapsed: 4294.158383369446\n",
            "Train Epoch: 50 [6400/40000 (16%)]\tLoss: 0.417082\n",
            "Train Epoch: 50 [12800/40000 (32%)]\tLoss: 0.555250\n",
            "Train Epoch: 50 [19200/40000 (48%)]\tLoss: 0.484861\n",
            "Train Epoch: 50 [25600/40000 (64%)]\tLoss: 0.573201\n",
            "Train Epoch: 50 [32000/40000 (80%)]\tLoss: 0.293286\n",
            "Train Epoch: 50 [38400/40000 (96%)]\tLoss: 0.640857\n",
            "\n",
            "Average loss: 0.2454, Accuracy: 37368/40000 (93.420%)\n",
            "\n",
            "Time Elapsed: 4381.275530338287\n",
            "Train Epoch: 51 [6400/40000 (16%)]\tLoss: 0.221858\n",
            "Train Epoch: 51 [12800/40000 (32%)]\tLoss: 0.445793\n",
            "Train Epoch: 51 [19200/40000 (48%)]\tLoss: 0.215131\n",
            "Train Epoch: 51 [25600/40000 (64%)]\tLoss: 0.380733\n",
            "Train Epoch: 51 [32000/40000 (80%)]\tLoss: 0.401726\n",
            "Train Epoch: 51 [38400/40000 (96%)]\tLoss: 0.358901\n",
            "\n",
            "Average loss: 0.3112, Accuracy: 37290/40000 (93.225%)\n",
            "\n",
            "Time Elapsed: 4466.611638307571\n",
            "Train Epoch: 52 [6400/40000 (16%)]\tLoss: 0.410620\n",
            "Train Epoch: 52 [12800/40000 (32%)]\tLoss: 0.601094\n",
            "Train Epoch: 52 [19200/40000 (48%)]\tLoss: 0.424124\n",
            "Train Epoch: 52 [25600/40000 (64%)]\tLoss: 0.459659\n",
            "Train Epoch: 52 [32000/40000 (80%)]\tLoss: 0.459210\n",
            "Train Epoch: 52 [38400/40000 (96%)]\tLoss: 0.350779\n",
            "\n",
            "Average loss: 0.3303, Accuracy: 36547/40000 (91.368%)\n",
            "\n",
            "Time Elapsed: 4551.749351263046\n",
            "Train Epoch: 53 [6400/40000 (16%)]\tLoss: 0.520683\n",
            "Train Epoch: 53 [12800/40000 (32%)]\tLoss: 0.299719\n",
            "Train Epoch: 53 [19200/40000 (48%)]\tLoss: 0.271257\n",
            "Train Epoch: 53 [25600/40000 (64%)]\tLoss: 0.348601\n",
            "Train Epoch: 53 [32000/40000 (80%)]\tLoss: 0.513310\n",
            "Train Epoch: 53 [38400/40000 (96%)]\tLoss: 0.307337\n",
            "\n",
            "Average loss: 0.2011, Accuracy: 37755/40000 (94.388%)\n",
            "\n",
            "Time Elapsed: 4636.913404464722\n",
            "Train Epoch: 54 [6400/40000 (16%)]\tLoss: 0.388096\n",
            "Train Epoch: 54 [12800/40000 (32%)]\tLoss: 0.259414\n",
            "Train Epoch: 54 [19200/40000 (48%)]\tLoss: 0.486621\n",
            "Train Epoch: 54 [25600/40000 (64%)]\tLoss: 0.303249\n",
            "Train Epoch: 54 [32000/40000 (80%)]\tLoss: 0.304478\n",
            "Train Epoch: 54 [38400/40000 (96%)]\tLoss: 0.283249\n",
            "\n",
            "Average loss: 0.1719, Accuracy: 37893/40000 (94.733%)\n",
            "\n",
            "Time Elapsed: 4722.236733913422\n",
            "Train Epoch: 55 [6400/40000 (16%)]\tLoss: 0.467706\n",
            "Train Epoch: 55 [12800/40000 (32%)]\tLoss: 0.542529\n",
            "Train Epoch: 55 [19200/40000 (48%)]\tLoss: 0.402540\n",
            "Train Epoch: 55 [25600/40000 (64%)]\tLoss: 0.385818\n",
            "Train Epoch: 55 [32000/40000 (80%)]\tLoss: 0.233067\n",
            "Train Epoch: 55 [38400/40000 (96%)]\tLoss: 0.414488\n",
            "\n",
            "Average loss: 0.1697, Accuracy: 37915/40000 (94.787%)\n",
            "\n",
            "Time Elapsed: 4809.885754585266\n",
            "Train Epoch: 56 [6400/40000 (16%)]\tLoss: 0.326427\n",
            "Train Epoch: 56 [12800/40000 (32%)]\tLoss: 0.429882\n",
            "Train Epoch: 56 [19200/40000 (48%)]\tLoss: 0.406079\n",
            "Train Epoch: 56 [25600/40000 (64%)]\tLoss: 0.609007\n",
            "Train Epoch: 56 [32000/40000 (80%)]\tLoss: 0.299875\n",
            "Train Epoch: 56 [38400/40000 (96%)]\tLoss: 0.584941\n",
            "\n",
            "Average loss: 0.1873, Accuracy: 37638/40000 (94.095%)\n",
            "\n",
            "Time Elapsed: 4895.080778121948\n",
            "Train Epoch: 57 [6400/40000 (16%)]\tLoss: 0.466988\n",
            "Train Epoch: 57 [12800/40000 (32%)]\tLoss: 0.751383\n",
            "Train Epoch: 57 [19200/40000 (48%)]\tLoss: 0.349020\n",
            "Train Epoch: 57 [25600/40000 (64%)]\tLoss: 0.584069\n",
            "Train Epoch: 57 [32000/40000 (80%)]\tLoss: 0.256944\n",
            "Train Epoch: 57 [38400/40000 (96%)]\tLoss: 0.619985\n",
            "\n",
            "Average loss: 0.1657, Accuracy: 37888/40000 (94.720%)\n",
            "\n",
            "Time Elapsed: 4980.195523023605\n",
            "Train Epoch: 58 [6400/40000 (16%)]\tLoss: 0.421447\n",
            "Train Epoch: 58 [12800/40000 (32%)]\tLoss: 0.399016\n",
            "Train Epoch: 58 [19200/40000 (48%)]\tLoss: 0.319578\n",
            "Train Epoch: 58 [25600/40000 (64%)]\tLoss: 0.371383\n",
            "Train Epoch: 58 [32000/40000 (80%)]\tLoss: 0.155381\n",
            "Train Epoch: 58 [38400/40000 (96%)]\tLoss: 0.292942\n",
            "\n",
            "Average loss: 0.1754, Accuracy: 37843/40000 (94.608%)\n",
            "\n",
            "Time Elapsed: 5065.518560171127\n",
            "Train Epoch: 59 [6400/40000 (16%)]\tLoss: 0.299353\n",
            "Train Epoch: 59 [12800/40000 (32%)]\tLoss: 0.714735\n",
            "Train Epoch: 59 [19200/40000 (48%)]\tLoss: 0.358245\n",
            "Train Epoch: 59 [25600/40000 (64%)]\tLoss: 0.229789\n",
            "Train Epoch: 59 [32000/40000 (80%)]\tLoss: 0.515307\n",
            "Train Epoch: 59 [38400/40000 (96%)]\tLoss: 0.480674\n",
            "\n",
            "Average loss: 0.1706, Accuracy: 37877/40000 (94.692%)\n",
            "\n",
            "Time Elapsed: 5150.952451705933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AmjQHAesjEsJ",
        "outputId": "a21e58bc-cea3-4254-b203-1df3da860c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9467
        }
      },
      "cell_type": "code",
      "source": [
        "start_epoch = 0\n",
        "n_epochs = 60\n",
        "\n",
        "model_dir = 'models'\n",
        "\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    train(epoch)\n",
        "    if epoch % 5 == 0:    \n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'epoch-full-{}.pth'.format(epoch)))\n",
        "    torch.cuda.empty_cache()\n",
        "    evaluate(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/40000 (16%)]\tLoss: 2.565303\n",
            "Train Epoch: 0 [12800/40000 (32%)]\tLoss: 2.293032\n",
            "Train Epoch: 0 [19200/40000 (48%)]\tLoss: 2.139401\n",
            "Train Epoch: 0 [25600/40000 (64%)]\tLoss: 2.290309\n",
            "Train Epoch: 0 [32000/40000 (80%)]\tLoss: 1.877378\n",
            "Train Epoch: 0 [38400/40000 (96%)]\tLoss: 2.104863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average loss: 2.0648, Accuracy: 10764/40000 (26.910%)\n",
            "\n",
            "Train Epoch: 1 [6400/40000 (16%)]\tLoss: 2.016990\n",
            "Train Epoch: 1 [12800/40000 (32%)]\tLoss: 1.842511\n",
            "Train Epoch: 1 [19200/40000 (48%)]\tLoss: 1.627758\n",
            "Train Epoch: 1 [25600/40000 (64%)]\tLoss: 1.671820\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 1.554312\n",
            "Train Epoch: 1 [38400/40000 (96%)]\tLoss: 1.455557\n",
            "\n",
            "Average loss: 1.2788, Accuracy: 23140/40000 (57.850%)\n",
            "\n",
            "Train Epoch: 2 [6400/40000 (16%)]\tLoss: 1.294898\n",
            "Train Epoch: 2 [12800/40000 (32%)]\tLoss: 1.442127\n",
            "Train Epoch: 2 [19200/40000 (48%)]\tLoss: 1.463770\n",
            "Train Epoch: 2 [25600/40000 (64%)]\tLoss: 1.125922\n",
            "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 1.334277\n",
            "Train Epoch: 2 [38400/40000 (96%)]\tLoss: 1.259514\n",
            "\n",
            "Average loss: 0.9741, Accuracy: 27563/40000 (68.907%)\n",
            "\n",
            "Train Epoch: 3 [6400/40000 (16%)]\tLoss: 1.303604\n",
            "Train Epoch: 3 [12800/40000 (32%)]\tLoss: 0.990251\n",
            "Train Epoch: 3 [19200/40000 (48%)]\tLoss: 1.502341\n",
            "Train Epoch: 3 [25600/40000 (64%)]\tLoss: 1.296941\n",
            "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 1.751211\n",
            "Train Epoch: 3 [38400/40000 (96%)]\tLoss: 1.028730\n",
            "\n",
            "Average loss: 0.8289, Accuracy: 29452/40000 (73.630%)\n",
            "\n",
            "Train Epoch: 4 [6400/40000 (16%)]\tLoss: 1.143757\n",
            "Train Epoch: 4 [12800/40000 (32%)]\tLoss: 0.914169\n",
            "Train Epoch: 4 [19200/40000 (48%)]\tLoss: 1.000951\n",
            "Train Epoch: 4 [25600/40000 (64%)]\tLoss: 1.178527\n",
            "Train Epoch: 4 [32000/40000 (80%)]\tLoss: 1.230335\n",
            "Train Epoch: 4 [38400/40000 (96%)]\tLoss: 1.155730\n",
            "\n",
            "Average loss: 0.7836, Accuracy: 29986/40000 (74.965%)\n",
            "\n",
            "Train Epoch: 5 [6400/40000 (16%)]\tLoss: 1.116450\n",
            "Train Epoch: 5 [12800/40000 (32%)]\tLoss: 0.864360\n",
            "Train Epoch: 5 [19200/40000 (48%)]\tLoss: 1.030485\n",
            "Train Epoch: 5 [25600/40000 (64%)]\tLoss: 0.976232\n",
            "Train Epoch: 5 [32000/40000 (80%)]\tLoss: 0.909410\n",
            "Train Epoch: 5 [38400/40000 (96%)]\tLoss: 0.906102\n",
            "\n",
            "Average loss: 0.7330, Accuracy: 30444/40000 (76.110%)\n",
            "\n",
            "Train Epoch: 6 [6400/40000 (16%)]\tLoss: 0.690974\n",
            "Train Epoch: 6 [12800/40000 (32%)]\tLoss: 0.830625\n",
            "Train Epoch: 6 [19200/40000 (48%)]\tLoss: 0.716428\n",
            "Train Epoch: 6 [25600/40000 (64%)]\tLoss: 1.103177\n",
            "Train Epoch: 6 [32000/40000 (80%)]\tLoss: 1.014164\n",
            "Train Epoch: 6 [38400/40000 (96%)]\tLoss: 0.878990\n",
            "\n",
            "Average loss: 0.5794, Accuracy: 32784/40000 (81.960%)\n",
            "\n",
            "Train Epoch: 7 [6400/40000 (16%)]\tLoss: 0.715971\n",
            "Train Epoch: 7 [12800/40000 (32%)]\tLoss: 0.948491\n",
            "Train Epoch: 7 [19200/40000 (48%)]\tLoss: 1.036013\n",
            "Train Epoch: 7 [25600/40000 (64%)]\tLoss: 0.895724\n",
            "Train Epoch: 7 [32000/40000 (80%)]\tLoss: 1.095820\n",
            "Train Epoch: 7 [38400/40000 (96%)]\tLoss: 0.751655\n",
            "\n",
            "Average loss: 0.5924, Accuracy: 32645/40000 (81.612%)\n",
            "\n",
            "Train Epoch: 8 [6400/40000 (16%)]\tLoss: 0.868903\n",
            "Train Epoch: 8 [12800/40000 (32%)]\tLoss: 0.897644\n",
            "Train Epoch: 8 [19200/40000 (48%)]\tLoss: 0.670628\n",
            "Train Epoch: 8 [25600/40000 (64%)]\tLoss: 0.682528\n",
            "Train Epoch: 8 [32000/40000 (80%)]\tLoss: 1.181380\n",
            "Train Epoch: 8 [38400/40000 (96%)]\tLoss: 0.532920\n",
            "\n",
            "Average loss: 0.4938, Accuracy: 34049/40000 (85.123%)\n",
            "\n",
            "Train Epoch: 9 [6400/40000 (16%)]\tLoss: 0.760022\n",
            "Train Epoch: 9 [12800/40000 (32%)]\tLoss: 0.876226\n",
            "Train Epoch: 9 [19200/40000 (48%)]\tLoss: 0.485487\n",
            "Train Epoch: 9 [25600/40000 (64%)]\tLoss: 0.880412\n",
            "Train Epoch: 9 [32000/40000 (80%)]\tLoss: 0.697220\n",
            "Train Epoch: 9 [38400/40000 (96%)]\tLoss: 0.765090\n",
            "\n",
            "Average loss: 0.5359, Accuracy: 33600/40000 (84.000%)\n",
            "\n",
            "Train Epoch: 10 [6400/40000 (16%)]\tLoss: 0.765192\n",
            "Train Epoch: 10 [12800/40000 (32%)]\tLoss: 0.717358\n",
            "Train Epoch: 10 [19200/40000 (48%)]\tLoss: 0.795789\n",
            "Train Epoch: 10 [25600/40000 (64%)]\tLoss: 0.617322\n",
            "Train Epoch: 10 [32000/40000 (80%)]\tLoss: 0.600483\n",
            "Train Epoch: 10 [38400/40000 (96%)]\tLoss: 1.023789\n",
            "\n",
            "Average loss: 0.5059, Accuracy: 34024/40000 (85.060%)\n",
            "\n",
            "Train Epoch: 11 [6400/40000 (16%)]\tLoss: 0.845677\n",
            "Train Epoch: 11 [12800/40000 (32%)]\tLoss: 0.746115\n",
            "Train Epoch: 11 [19200/40000 (48%)]\tLoss: 0.462012\n",
            "Train Epoch: 11 [25600/40000 (64%)]\tLoss: 0.894837\n",
            "Train Epoch: 11 [32000/40000 (80%)]\tLoss: 0.757295\n",
            "Train Epoch: 11 [38400/40000 (96%)]\tLoss: 0.806281\n",
            "\n",
            "Average loss: 0.3995, Accuracy: 34996/40000 (87.490%)\n",
            "\n",
            "Train Epoch: 12 [6400/40000 (16%)]\tLoss: 0.648257\n",
            "Train Epoch: 12 [12800/40000 (32%)]\tLoss: 0.414195\n",
            "Train Epoch: 12 [19200/40000 (48%)]\tLoss: 0.503984\n",
            "Train Epoch: 12 [25600/40000 (64%)]\tLoss: 0.640144\n",
            "Train Epoch: 12 [32000/40000 (80%)]\tLoss: 0.811492\n",
            "Train Epoch: 12 [38400/40000 (96%)]\tLoss: 0.510411\n",
            "\n",
            "Average loss: 0.4613, Accuracy: 34793/40000 (86.983%)\n",
            "\n",
            "Train Epoch: 13 [6400/40000 (16%)]\tLoss: 0.710681\n",
            "Train Epoch: 13 [12800/40000 (32%)]\tLoss: 0.585420\n",
            "Train Epoch: 13 [19200/40000 (48%)]\tLoss: 0.869678\n",
            "Train Epoch: 13 [25600/40000 (64%)]\tLoss: 0.616938\n",
            "Train Epoch: 13 [32000/40000 (80%)]\tLoss: 1.023672\n",
            "Train Epoch: 13 [38400/40000 (96%)]\tLoss: 0.748819\n",
            "\n",
            "Average loss: 0.3736, Accuracy: 35493/40000 (88.733%)\n",
            "\n",
            "Train Epoch: 14 [6400/40000 (16%)]\tLoss: 0.436045\n",
            "Train Epoch: 14 [12800/40000 (32%)]\tLoss: 0.676230\n",
            "Train Epoch: 14 [19200/40000 (48%)]\tLoss: 0.666617\n",
            "Train Epoch: 14 [25600/40000 (64%)]\tLoss: 0.543195\n",
            "Train Epoch: 14 [32000/40000 (80%)]\tLoss: 1.151815\n",
            "Train Epoch: 14 [38400/40000 (96%)]\tLoss: 1.199239\n",
            "\n",
            "Average loss: 0.4531, Accuracy: 34318/40000 (85.795%)\n",
            "\n",
            "Train Epoch: 15 [6400/40000 (16%)]\tLoss: 0.662805\n",
            "Train Epoch: 15 [12800/40000 (32%)]\tLoss: 0.383310\n",
            "Train Epoch: 15 [19200/40000 (48%)]\tLoss: 0.496208\n",
            "Train Epoch: 15 [25600/40000 (64%)]\tLoss: 1.037003\n",
            "Train Epoch: 15 [32000/40000 (80%)]\tLoss: 0.741499\n",
            "Train Epoch: 15 [38400/40000 (96%)]\tLoss: 0.452836\n",
            "\n",
            "Average loss: 0.4786, Accuracy: 33937/40000 (84.843%)\n",
            "\n",
            "Train Epoch: 16 [6400/40000 (16%)]\tLoss: 0.750655\n",
            "Train Epoch: 16 [12800/40000 (32%)]\tLoss: 0.345935\n",
            "Train Epoch: 16 [19200/40000 (48%)]\tLoss: 0.539703\n",
            "Train Epoch: 16 [25600/40000 (64%)]\tLoss: 0.539982\n",
            "Train Epoch: 16 [32000/40000 (80%)]\tLoss: 0.804841\n",
            "Train Epoch: 16 [38400/40000 (96%)]\tLoss: 0.611330\n",
            "\n",
            "Average loss: 0.3688, Accuracy: 35477/40000 (88.692%)\n",
            "\n",
            "Train Epoch: 17 [6400/40000 (16%)]\tLoss: 0.433302\n",
            "Train Epoch: 17 [12800/40000 (32%)]\tLoss: 0.689454\n",
            "Train Epoch: 17 [19200/40000 (48%)]\tLoss: 0.726721\n",
            "Train Epoch: 17 [25600/40000 (64%)]\tLoss: 0.975471\n",
            "Train Epoch: 17 [32000/40000 (80%)]\tLoss: 0.526510\n",
            "Train Epoch: 17 [38400/40000 (96%)]\tLoss: 0.596936\n",
            "\n",
            "Average loss: 0.3766, Accuracy: 35502/40000 (88.755%)\n",
            "\n",
            "Train Epoch: 18 [6400/40000 (16%)]\tLoss: 0.592018\n",
            "Train Epoch: 18 [12800/40000 (32%)]\tLoss: 0.542142\n",
            "Train Epoch: 18 [19200/40000 (48%)]\tLoss: 0.470472\n",
            "Train Epoch: 18 [25600/40000 (64%)]\tLoss: 0.397621\n",
            "Train Epoch: 18 [32000/40000 (80%)]\tLoss: 0.569923\n",
            "Train Epoch: 18 [38400/40000 (96%)]\tLoss: 0.772205\n",
            "\n",
            "Average loss: 0.3204, Accuracy: 36110/40000 (90.275%)\n",
            "\n",
            "Train Epoch: 19 [6400/40000 (16%)]\tLoss: 0.481135\n",
            "Train Epoch: 19 [12800/40000 (32%)]\tLoss: 0.426166\n",
            "Train Epoch: 19 [19200/40000 (48%)]\tLoss: 0.389702\n",
            "Train Epoch: 19 [25600/40000 (64%)]\tLoss: 0.678949\n",
            "Train Epoch: 19 [32000/40000 (80%)]\tLoss: 0.492560\n",
            "Train Epoch: 19 [38400/40000 (96%)]\tLoss: 0.421224\n",
            "\n",
            "Average loss: 0.3090, Accuracy: 36192/40000 (90.480%)\n",
            "\n",
            "Train Epoch: 20 [6400/40000 (16%)]\tLoss: 0.660259\n",
            "Train Epoch: 20 [12800/40000 (32%)]\tLoss: 0.660528\n",
            "Train Epoch: 20 [19200/40000 (48%)]\tLoss: 0.328598\n",
            "Train Epoch: 20 [25600/40000 (64%)]\tLoss: 0.510956\n",
            "Train Epoch: 20 [32000/40000 (80%)]\tLoss: 0.497592\n",
            "Train Epoch: 20 [38400/40000 (96%)]\tLoss: 0.593042\n",
            "\n",
            "Average loss: 0.3103, Accuracy: 36053/40000 (90.132%)\n",
            "\n",
            "Train Epoch: 21 [6400/40000 (16%)]\tLoss: 0.630985\n",
            "Train Epoch: 21 [12800/40000 (32%)]\tLoss: 0.380046\n",
            "Train Epoch: 21 [19200/40000 (48%)]\tLoss: 0.696277\n",
            "Train Epoch: 21 [25600/40000 (64%)]\tLoss: 0.361031\n",
            "Train Epoch: 21 [32000/40000 (80%)]\tLoss: 0.823386\n",
            "Train Epoch: 21 [38400/40000 (96%)]\tLoss: 0.536608\n",
            "\n",
            "Average loss: 0.3544, Accuracy: 35566/40000 (88.915%)\n",
            "\n",
            "Train Epoch: 22 [6400/40000 (16%)]\tLoss: 0.520751\n",
            "Train Epoch: 22 [12800/40000 (32%)]\tLoss: 0.394757\n",
            "Train Epoch: 22 [19200/40000 (48%)]\tLoss: 0.740811\n",
            "Train Epoch: 22 [25600/40000 (64%)]\tLoss: 0.710506\n",
            "Train Epoch: 22 [32000/40000 (80%)]\tLoss: 0.371720\n",
            "Train Epoch: 22 [38400/40000 (96%)]\tLoss: 0.426547\n",
            "\n",
            "Average loss: 0.3166, Accuracy: 36344/40000 (90.860%)\n",
            "\n",
            "Train Epoch: 23 [6400/40000 (16%)]\tLoss: 0.591742\n",
            "Train Epoch: 23 [12800/40000 (32%)]\tLoss: 0.481255\n",
            "Train Epoch: 23 [19200/40000 (48%)]\tLoss: 0.415253\n",
            "Train Epoch: 23 [25600/40000 (64%)]\tLoss: 0.627066\n",
            "Train Epoch: 23 [32000/40000 (80%)]\tLoss: 0.499213\n",
            "Train Epoch: 23 [38400/40000 (96%)]\tLoss: 0.809451\n",
            "\n",
            "Average loss: 0.2905, Accuracy: 36351/40000 (90.877%)\n",
            "\n",
            "Train Epoch: 24 [6400/40000 (16%)]\tLoss: 0.645128\n",
            "Train Epoch: 24 [12800/40000 (32%)]\tLoss: 0.480196\n",
            "Train Epoch: 24 [19200/40000 (48%)]\tLoss: 0.269840\n",
            "Train Epoch: 24 [25600/40000 (64%)]\tLoss: 0.641080\n",
            "Train Epoch: 24 [32000/40000 (80%)]\tLoss: 0.375754\n",
            "Train Epoch: 24 [38400/40000 (96%)]\tLoss: 0.521819\n",
            "\n",
            "Average loss: 0.2664, Accuracy: 36731/40000 (91.828%)\n",
            "\n",
            "Train Epoch: 25 [6400/40000 (16%)]\tLoss: 0.643999\n",
            "Train Epoch: 25 [12800/40000 (32%)]\tLoss: 0.758449\n",
            "Train Epoch: 25 [19200/40000 (48%)]\tLoss: 0.351373\n",
            "Train Epoch: 25 [25600/40000 (64%)]\tLoss: 0.536561\n",
            "Train Epoch: 25 [32000/40000 (80%)]\tLoss: 0.368020\n",
            "Train Epoch: 25 [38400/40000 (96%)]\tLoss: 0.672275\n",
            "\n",
            "Average loss: 0.2670, Accuracy: 36800/40000 (92.000%)\n",
            "\n",
            "Train Epoch: 26 [6400/40000 (16%)]\tLoss: 0.561323\n",
            "Train Epoch: 26 [12800/40000 (32%)]\tLoss: 0.446085\n",
            "Train Epoch: 26 [19200/40000 (48%)]\tLoss: 0.458896\n",
            "Train Epoch: 26 [25600/40000 (64%)]\tLoss: 0.535300\n",
            "Train Epoch: 26 [32000/40000 (80%)]\tLoss: 0.754308\n",
            "Train Epoch: 26 [38400/40000 (96%)]\tLoss: 0.514026\n",
            "\n",
            "Average loss: 0.2622, Accuracy: 36680/40000 (91.700%)\n",
            "\n",
            "Train Epoch: 27 [6400/40000 (16%)]\tLoss: 0.646983\n",
            "Train Epoch: 27 [12800/40000 (32%)]\tLoss: 0.352395\n",
            "Train Epoch: 27 [19200/40000 (48%)]\tLoss: 0.429570\n",
            "Train Epoch: 27 [25600/40000 (64%)]\tLoss: 0.525115\n",
            "Train Epoch: 27 [32000/40000 (80%)]\tLoss: 0.392463\n",
            "Train Epoch: 27 [38400/40000 (96%)]\tLoss: 0.412198\n",
            "\n",
            "Average loss: 0.2853, Accuracy: 36625/40000 (91.562%)\n",
            "\n",
            "Train Epoch: 28 [6400/40000 (16%)]\tLoss: 0.743294\n",
            "Train Epoch: 28 [12800/40000 (32%)]\tLoss: 0.496400\n",
            "Train Epoch: 28 [19200/40000 (48%)]\tLoss: 0.367329\n",
            "Train Epoch: 28 [25600/40000 (64%)]\tLoss: 0.524103\n",
            "Train Epoch: 28 [32000/40000 (80%)]\tLoss: 0.535224\n",
            "Train Epoch: 28 [38400/40000 (96%)]\tLoss: 0.412434\n",
            "\n",
            "Average loss: 0.3036, Accuracy: 36634/40000 (91.585%)\n",
            "\n",
            "Train Epoch: 29 [6400/40000 (16%)]\tLoss: 0.471218\n",
            "Train Epoch: 29 [12800/40000 (32%)]\tLoss: 0.490594\n",
            "Train Epoch: 29 [19200/40000 (48%)]\tLoss: 0.319964\n",
            "Train Epoch: 29 [25600/40000 (64%)]\tLoss: 0.896359\n",
            "Train Epoch: 29 [32000/40000 (80%)]\tLoss: 0.757578\n",
            "Train Epoch: 29 [38400/40000 (96%)]\tLoss: 0.424824\n",
            "\n",
            "Average loss: 0.2437, Accuracy: 36991/40000 (92.478%)\n",
            "\n",
            "Train Epoch: 30 [6400/40000 (16%)]\tLoss: 0.654024\n",
            "Train Epoch: 30 [12800/40000 (32%)]\tLoss: 0.420410\n",
            "Train Epoch: 30 [19200/40000 (48%)]\tLoss: 0.412772\n",
            "Train Epoch: 30 [25600/40000 (64%)]\tLoss: 0.442452\n",
            "Train Epoch: 30 [32000/40000 (80%)]\tLoss: 0.560865\n",
            "Train Epoch: 30 [38400/40000 (96%)]\tLoss: 0.483917\n",
            "\n",
            "Average loss: 0.2337, Accuracy: 37127/40000 (92.817%)\n",
            "\n",
            "Train Epoch: 31 [6400/40000 (16%)]\tLoss: 0.431192\n",
            "Train Epoch: 31 [12800/40000 (32%)]\tLoss: 0.860812\n",
            "Train Epoch: 31 [19200/40000 (48%)]\tLoss: 0.384819\n",
            "Train Epoch: 31 [25600/40000 (64%)]\tLoss: 0.420881\n",
            "Train Epoch: 31 [32000/40000 (80%)]\tLoss: 0.385749\n",
            "Train Epoch: 31 [38400/40000 (96%)]\tLoss: 0.736323\n",
            "\n",
            "Average loss: 0.2286, Accuracy: 37145/40000 (92.862%)\n",
            "\n",
            "Train Epoch: 32 [6400/40000 (16%)]\tLoss: 0.494892\n",
            "Train Epoch: 32 [12800/40000 (32%)]\tLoss: 0.430590\n",
            "Train Epoch: 32 [19200/40000 (48%)]\tLoss: 0.567483\n",
            "Train Epoch: 32 [25600/40000 (64%)]\tLoss: 0.380444\n",
            "Train Epoch: 32 [32000/40000 (80%)]\tLoss: 0.823335\n",
            "Train Epoch: 32 [38400/40000 (96%)]\tLoss: 0.961237\n",
            "\n",
            "Average loss: 0.2640, Accuracy: 36948/40000 (92.370%)\n",
            "\n",
            "Train Epoch: 33 [6400/40000 (16%)]\tLoss: 0.415719\n",
            "Train Epoch: 33 [12800/40000 (32%)]\tLoss: 0.378256\n",
            "Train Epoch: 33 [19200/40000 (48%)]\tLoss: 0.572613\n",
            "Train Epoch: 33 [25600/40000 (64%)]\tLoss: 0.299826\n",
            "Train Epoch: 33 [32000/40000 (80%)]\tLoss: 0.329622\n",
            "Train Epoch: 33 [38400/40000 (96%)]\tLoss: 0.336508\n",
            "\n",
            "Average loss: 0.2361, Accuracy: 37189/40000 (92.972%)\n",
            "\n",
            "Train Epoch: 34 [6400/40000 (16%)]\tLoss: 0.550570\n",
            "Train Epoch: 34 [12800/40000 (32%)]\tLoss: 0.524952\n",
            "Train Epoch: 34 [19200/40000 (48%)]\tLoss: 0.744373\n",
            "Train Epoch: 34 [25600/40000 (64%)]\tLoss: 0.307528\n",
            "Train Epoch: 34 [32000/40000 (80%)]\tLoss: 0.943587\n",
            "Train Epoch: 34 [38400/40000 (96%)]\tLoss: 0.399990\n",
            "\n",
            "Average loss: 0.2352, Accuracy: 37099/40000 (92.748%)\n",
            "\n",
            "Train Epoch: 35 [6400/40000 (16%)]\tLoss: 0.523260\n",
            "Train Epoch: 35 [12800/40000 (32%)]\tLoss: 0.475183\n",
            "Train Epoch: 35 [19200/40000 (48%)]\tLoss: 0.541856\n",
            "Train Epoch: 35 [25600/40000 (64%)]\tLoss: 0.511537\n",
            "Train Epoch: 35 [32000/40000 (80%)]\tLoss: 0.498956\n",
            "Train Epoch: 35 [38400/40000 (96%)]\tLoss: 0.535241\n",
            "\n",
            "Average loss: 0.2371, Accuracy: 36993/40000 (92.483%)\n",
            "\n",
            "Train Epoch: 36 [6400/40000 (16%)]\tLoss: 0.371375\n",
            "Train Epoch: 36 [12800/40000 (32%)]\tLoss: 0.377894\n",
            "Train Epoch: 36 [19200/40000 (48%)]\tLoss: 0.311554\n",
            "Train Epoch: 36 [25600/40000 (64%)]\tLoss: 0.502520\n",
            "Train Epoch: 36 [32000/40000 (80%)]\tLoss: 0.568253\n",
            "Train Epoch: 36 [38400/40000 (96%)]\tLoss: 0.429209\n",
            "\n",
            "Average loss: 0.2654, Accuracy: 37261/40000 (93.153%)\n",
            "\n",
            "Train Epoch: 37 [6400/40000 (16%)]\tLoss: 0.379504\n",
            "Train Epoch: 37 [12800/40000 (32%)]\tLoss: 0.336992\n",
            "Train Epoch: 37 [19200/40000 (48%)]\tLoss: 0.469155\n",
            "Train Epoch: 37 [25600/40000 (64%)]\tLoss: 0.274984\n",
            "Train Epoch: 37 [32000/40000 (80%)]\tLoss: 0.365607\n",
            "Train Epoch: 37 [38400/40000 (96%)]\tLoss: 0.318376\n",
            "\n",
            "Average loss: 0.2235, Accuracy: 37170/40000 (92.925%)\n",
            "\n",
            "Train Epoch: 38 [6400/40000 (16%)]\tLoss: 0.812458\n",
            "Train Epoch: 38 [12800/40000 (32%)]\tLoss: 0.562055\n",
            "Train Epoch: 38 [19200/40000 (48%)]\tLoss: 0.507581\n",
            "Train Epoch: 38 [25600/40000 (64%)]\tLoss: 0.542045\n",
            "Train Epoch: 38 [32000/40000 (80%)]\tLoss: 0.327669\n",
            "Train Epoch: 38 [38400/40000 (96%)]\tLoss: 0.392029\n",
            "\n",
            "Average loss: 0.2352, Accuracy: 37326/40000 (93.315%)\n",
            "\n",
            "Train Epoch: 39 [6400/40000 (16%)]\tLoss: 0.139591\n",
            "Train Epoch: 39 [12800/40000 (32%)]\tLoss: 0.513392\n",
            "Train Epoch: 39 [19200/40000 (48%)]\tLoss: 0.689897\n",
            "Train Epoch: 39 [25600/40000 (64%)]\tLoss: 0.439030\n",
            "Train Epoch: 39 [32000/40000 (80%)]\tLoss: 0.430801\n",
            "Train Epoch: 39 [38400/40000 (96%)]\tLoss: 0.547617\n",
            "\n",
            "Average loss: 0.2421, Accuracy: 36946/40000 (92.365%)\n",
            "\n",
            "Train Epoch: 40 [6400/40000 (16%)]\tLoss: 0.405037\n",
            "Train Epoch: 40 [12800/40000 (32%)]\tLoss: 0.464048\n",
            "Train Epoch: 40 [19200/40000 (48%)]\tLoss: 0.376653\n",
            "Train Epoch: 40 [25600/40000 (64%)]\tLoss: 0.549759\n",
            "Train Epoch: 40 [32000/40000 (80%)]\tLoss: 0.606290\n",
            "Train Epoch: 40 [38400/40000 (96%)]\tLoss: 0.300484\n",
            "\n",
            "Average loss: 0.2630, Accuracy: 37168/40000 (92.920%)\n",
            "\n",
            "Train Epoch: 41 [6400/40000 (16%)]\tLoss: 0.806587\n",
            "Train Epoch: 41 [12800/40000 (32%)]\tLoss: 0.301431\n",
            "Train Epoch: 41 [19200/40000 (48%)]\tLoss: 0.491513\n",
            "Train Epoch: 41 [25600/40000 (64%)]\tLoss: 0.555019\n",
            "Train Epoch: 41 [32000/40000 (80%)]\tLoss: 0.252152\n",
            "Train Epoch: 41 [38400/40000 (96%)]\tLoss: 0.366323\n",
            "\n",
            "Average loss: 0.1965, Accuracy: 37584/40000 (93.960%)\n",
            "\n",
            "Train Epoch: 42 [6400/40000 (16%)]\tLoss: 0.541758\n",
            "Train Epoch: 42 [12800/40000 (32%)]\tLoss: 0.469049\n",
            "Train Epoch: 42 [19200/40000 (48%)]\tLoss: 0.315784\n",
            "Train Epoch: 42 [25600/40000 (64%)]\tLoss: 0.459659\n",
            "Train Epoch: 42 [32000/40000 (80%)]\tLoss: 0.628391\n",
            "Train Epoch: 42 [38400/40000 (96%)]\tLoss: 0.414920\n",
            "\n",
            "Average loss: 0.2383, Accuracy: 37258/40000 (93.145%)\n",
            "\n",
            "Train Epoch: 43 [6400/40000 (16%)]\tLoss: 0.554529\n",
            "Train Epoch: 43 [12800/40000 (32%)]\tLoss: 0.498327\n",
            "Train Epoch: 43 [19200/40000 (48%)]\tLoss: 0.399529\n",
            "Train Epoch: 43 [25600/40000 (64%)]\tLoss: 0.604692\n",
            "Train Epoch: 43 [32000/40000 (80%)]\tLoss: 0.429501\n",
            "Train Epoch: 43 [38400/40000 (96%)]\tLoss: 0.412676\n",
            "\n",
            "Average loss: 0.2759, Accuracy: 37229/40000 (93.073%)\n",
            "\n",
            "Train Epoch: 44 [6400/40000 (16%)]\tLoss: 0.417775\n",
            "Train Epoch: 44 [12800/40000 (32%)]\tLoss: 0.500811\n",
            "Train Epoch: 44 [19200/40000 (48%)]\tLoss: 0.363185\n",
            "Train Epoch: 44 [25600/40000 (64%)]\tLoss: 0.662813\n",
            "Train Epoch: 44 [32000/40000 (80%)]\tLoss: 0.634776\n",
            "Train Epoch: 44 [38400/40000 (96%)]\tLoss: 0.410107\n",
            "\n",
            "Average loss: 0.2050, Accuracy: 37581/40000 (93.953%)\n",
            "\n",
            "Train Epoch: 45 [6400/40000 (16%)]\tLoss: 0.268284\n",
            "Train Epoch: 45 [12800/40000 (32%)]\tLoss: 0.439552\n",
            "Train Epoch: 45 [19200/40000 (48%)]\tLoss: 0.611022\n",
            "Train Epoch: 45 [25600/40000 (64%)]\tLoss: 0.431004\n",
            "Train Epoch: 45 [32000/40000 (80%)]\tLoss: 0.319673\n",
            "Train Epoch: 45 [38400/40000 (96%)]\tLoss: 0.190067\n",
            "\n",
            "Average loss: 0.1844, Accuracy: 37731/40000 (94.328%)\n",
            "\n",
            "Train Epoch: 46 [6400/40000 (16%)]\tLoss: 0.599802\n",
            "Train Epoch: 46 [12800/40000 (32%)]\tLoss: 0.382113\n",
            "Train Epoch: 46 [19200/40000 (48%)]\tLoss: 0.331764\n",
            "Train Epoch: 46 [25600/40000 (64%)]\tLoss: 0.502527\n",
            "Train Epoch: 46 [32000/40000 (80%)]\tLoss: 0.306917\n",
            "Train Epoch: 46 [38400/40000 (96%)]\tLoss: 0.546156\n",
            "\n",
            "Average loss: 0.1985, Accuracy: 37624/40000 (94.060%)\n",
            "\n",
            "Train Epoch: 47 [6400/40000 (16%)]\tLoss: 0.425082\n",
            "Train Epoch: 47 [12800/40000 (32%)]\tLoss: 0.513887\n",
            "Train Epoch: 47 [19200/40000 (48%)]\tLoss: 0.391048\n",
            "Train Epoch: 47 [25600/40000 (64%)]\tLoss: 0.303501\n",
            "Train Epoch: 47 [32000/40000 (80%)]\tLoss: 0.319332\n",
            "Train Epoch: 47 [38400/40000 (96%)]\tLoss: 0.413927\n",
            "\n",
            "Average loss: 0.1895, Accuracy: 37601/40000 (94.002%)\n",
            "\n",
            "Train Epoch: 48 [6400/40000 (16%)]\tLoss: 0.375120\n",
            "Train Epoch: 48 [12800/40000 (32%)]\tLoss: 0.362487\n",
            "Train Epoch: 48 [19200/40000 (48%)]\tLoss: 0.291640\n",
            "Train Epoch: 48 [25600/40000 (64%)]\tLoss: 0.414770\n",
            "Train Epoch: 48 [32000/40000 (80%)]\tLoss: 0.526204\n",
            "Train Epoch: 48 [38400/40000 (96%)]\tLoss: 0.323100\n",
            "\n",
            "Average loss: 0.1864, Accuracy: 37663/40000 (94.157%)\n",
            "\n",
            "Train Epoch: 49 [6400/40000 (16%)]\tLoss: 0.432926\n",
            "Train Epoch: 49 [12800/40000 (32%)]\tLoss: 0.445137\n",
            "Train Epoch: 49 [19200/40000 (48%)]\tLoss: 0.553671\n",
            "Train Epoch: 49 [25600/40000 (64%)]\tLoss: 0.255913\n",
            "Train Epoch: 49 [32000/40000 (80%)]\tLoss: 0.384679\n",
            "Train Epoch: 49 [38400/40000 (96%)]\tLoss: 0.538686\n",
            "\n",
            "Average loss: 0.1991, Accuracy: 37604/40000 (94.010%)\n",
            "\n",
            "Train Epoch: 50 [6400/40000 (16%)]\tLoss: 0.525798\n",
            "Train Epoch: 50 [12800/40000 (32%)]\tLoss: 0.308971\n",
            "Train Epoch: 50 [19200/40000 (48%)]\tLoss: 0.224975\n",
            "Train Epoch: 50 [25600/40000 (64%)]\tLoss: 0.634132\n",
            "Train Epoch: 50 [32000/40000 (80%)]\tLoss: 0.502395\n",
            "Train Epoch: 50 [38400/40000 (96%)]\tLoss: 0.287576\n",
            "\n",
            "Average loss: 0.1786, Accuracy: 37763/40000 (94.407%)\n",
            "\n",
            "Train Epoch: 51 [6400/40000 (16%)]\tLoss: 0.325217\n",
            "Train Epoch: 51 [12800/40000 (32%)]\tLoss: 0.345790\n",
            "Train Epoch: 51 [19200/40000 (48%)]\tLoss: 0.422547\n",
            "Train Epoch: 51 [25600/40000 (64%)]\tLoss: 0.127668\n",
            "Train Epoch: 51 [32000/40000 (80%)]\tLoss: 0.732776\n",
            "Train Epoch: 51 [38400/40000 (96%)]\tLoss: 0.308235\n",
            "\n",
            "Average loss: 0.1832, Accuracy: 37792/40000 (94.480%)\n",
            "\n",
            "Train Epoch: 52 [6400/40000 (16%)]\tLoss: 0.245737\n",
            "Train Epoch: 52 [12800/40000 (32%)]\tLoss: 0.322899\n",
            "Train Epoch: 52 [19200/40000 (48%)]\tLoss: 0.384598\n",
            "Train Epoch: 52 [25600/40000 (64%)]\tLoss: 0.473512\n",
            "Train Epoch: 52 [32000/40000 (80%)]\tLoss: 0.350928\n",
            "Train Epoch: 52 [38400/40000 (96%)]\tLoss: 0.737465\n",
            "\n",
            "Average loss: 0.1782, Accuracy: 37802/40000 (94.505%)\n",
            "\n",
            "Train Epoch: 53 [6400/40000 (16%)]\tLoss: 0.320495\n",
            "Train Epoch: 53 [12800/40000 (32%)]\tLoss: 0.512675\n",
            "Train Epoch: 53 [19200/40000 (48%)]\tLoss: 0.270786\n",
            "Train Epoch: 53 [25600/40000 (64%)]\tLoss: 0.605819\n",
            "Train Epoch: 53 [32000/40000 (80%)]\tLoss: 0.531761\n",
            "Train Epoch: 53 [38400/40000 (96%)]\tLoss: 0.274572\n",
            "\n",
            "Average loss: 0.1766, Accuracy: 37797/40000 (94.493%)\n",
            "\n",
            "Train Epoch: 54 [6400/40000 (16%)]\tLoss: 0.329850\n",
            "Train Epoch: 54 [12800/40000 (32%)]\tLoss: 0.237151\n",
            "Train Epoch: 54 [19200/40000 (48%)]\tLoss: 0.205420\n",
            "Train Epoch: 54 [25600/40000 (64%)]\tLoss: 0.150566\n",
            "Train Epoch: 54 [32000/40000 (80%)]\tLoss: 0.283943\n",
            "Train Epoch: 54 [38400/40000 (96%)]\tLoss: 0.383681\n",
            "\n",
            "Average loss: 0.2104, Accuracy: 37733/40000 (94.332%)\n",
            "\n",
            "Train Epoch: 55 [6400/40000 (16%)]\tLoss: 0.286123\n",
            "Train Epoch: 55 [12800/40000 (32%)]\tLoss: 0.656702\n",
            "Train Epoch: 55 [19200/40000 (48%)]\tLoss: 0.407497\n",
            "Train Epoch: 55 [25600/40000 (64%)]\tLoss: 0.420846\n",
            "Train Epoch: 55 [32000/40000 (80%)]\tLoss: 0.310694\n",
            "Train Epoch: 55 [38400/40000 (96%)]\tLoss: 0.387511\n",
            "\n",
            "Average loss: 0.1782, Accuracy: 37878/40000 (94.695%)\n",
            "\n",
            "Train Epoch: 56 [6400/40000 (16%)]\tLoss: 0.287351\n",
            "Train Epoch: 56 [12800/40000 (32%)]\tLoss: 0.434026\n",
            "Train Epoch: 56 [19200/40000 (48%)]\tLoss: 0.329441\n",
            "Train Epoch: 56 [25600/40000 (64%)]\tLoss: 0.307848\n",
            "Train Epoch: 56 [32000/40000 (80%)]\tLoss: 0.365466\n",
            "Train Epoch: 56 [38400/40000 (96%)]\tLoss: 0.367434\n",
            "\n",
            "Average loss: 0.1775, Accuracy: 37759/40000 (94.397%)\n",
            "\n",
            "Train Epoch: 57 [6400/40000 (16%)]\tLoss: 0.519322\n",
            "Train Epoch: 57 [12800/40000 (32%)]\tLoss: 0.240567\n",
            "Train Epoch: 57 [19200/40000 (48%)]\tLoss: 0.418134\n",
            "Train Epoch: 57 [25600/40000 (64%)]\tLoss: 0.278023\n",
            "Train Epoch: 57 [32000/40000 (80%)]\tLoss: 0.277587\n",
            "Train Epoch: 57 [38400/40000 (96%)]\tLoss: 0.212514\n",
            "\n",
            "Average loss: 0.1963, Accuracy: 37597/40000 (93.993%)\n",
            "\n",
            "Train Epoch: 58 [6400/40000 (16%)]\tLoss: 0.478369\n",
            "Train Epoch: 58 [12800/40000 (32%)]\tLoss: 0.340213\n",
            "Train Epoch: 58 [19200/40000 (48%)]\tLoss: 0.356811\n",
            "Train Epoch: 58 [25600/40000 (64%)]\tLoss: 0.321764\n",
            "Train Epoch: 58 [32000/40000 (80%)]\tLoss: 0.322438\n",
            "Train Epoch: 58 [38400/40000 (96%)]\tLoss: 0.475083\n",
            "\n",
            "Average loss: 0.1710, Accuracy: 37838/40000 (94.595%)\n",
            "\n",
            "Train Epoch: 59 [6400/40000 (16%)]\tLoss: 0.590129\n",
            "Train Epoch: 59 [12800/40000 (32%)]\tLoss: 0.320930\n",
            "Train Epoch: 59 [19200/40000 (48%)]\tLoss: 0.642162\n",
            "Train Epoch: 59 [25600/40000 (64%)]\tLoss: 0.160081\n",
            "Train Epoch: 59 [32000/40000 (80%)]\tLoss: 0.209636\n",
            "Train Epoch: 59 [38400/40000 (96%)]\tLoss: 0.460860\n",
            "\n",
            "Average loss: 0.1697, Accuracy: 37870/40000 (94.675%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "maPCtNERP8iX",
        "colab_type": "code",
        "outputId": "067d5e65-7e80-4932-c2f4-d40a355cb4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9467
        }
      },
      "cell_type": "code",
      "source": [
        "start_epoch = 60\n",
        "n_epochs = 120\n",
        "\n",
        "model_dir = 'models'\n",
        "\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    train(epoch)\n",
        "    if epoch % 5 == 0:    \n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'epoch-full-{}.pth'.format(epoch)))\n",
        "    torch.cuda.empty_cache()\n",
        "    evaluate(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 60 [6400/40000 (16%)]\tLoss: 0.347319\n",
            "Train Epoch: 60 [12800/40000 (32%)]\tLoss: 0.496886\n",
            "Train Epoch: 60 [19200/40000 (48%)]\tLoss: 0.507287\n",
            "Train Epoch: 60 [25600/40000 (64%)]\tLoss: 0.374577\n",
            "Train Epoch: 60 [32000/40000 (80%)]\tLoss: 0.269911\n",
            "Train Epoch: 60 [38400/40000 (96%)]\tLoss: 0.254242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average loss: 0.1564, Accuracy: 37997/40000 (94.993%)\n",
            "\n",
            "Train Epoch: 61 [6400/40000 (16%)]\tLoss: 0.758489\n",
            "Train Epoch: 61 [12800/40000 (32%)]\tLoss: 0.579518\n",
            "Train Epoch: 61 [19200/40000 (48%)]\tLoss: 0.466813\n",
            "Train Epoch: 61 [25600/40000 (64%)]\tLoss: 0.663823\n",
            "Train Epoch: 61 [32000/40000 (80%)]\tLoss: 0.429816\n",
            "Train Epoch: 61 [38400/40000 (96%)]\tLoss: 0.420400\n",
            "\n",
            "Average loss: 0.1608, Accuracy: 37987/40000 (94.968%)\n",
            "\n",
            "Train Epoch: 62 [6400/40000 (16%)]\tLoss: 0.354752\n",
            "Train Epoch: 62 [12800/40000 (32%)]\tLoss: 0.325874\n",
            "Train Epoch: 62 [19200/40000 (48%)]\tLoss: 0.360470\n",
            "Train Epoch: 62 [25600/40000 (64%)]\tLoss: 0.195135\n",
            "Train Epoch: 62 [32000/40000 (80%)]\tLoss: 0.312111\n",
            "Train Epoch: 62 [38400/40000 (96%)]\tLoss: 0.337495\n",
            "\n",
            "Average loss: 0.1621, Accuracy: 37973/40000 (94.933%)\n",
            "\n",
            "Train Epoch: 63 [6400/40000 (16%)]\tLoss: 0.603254\n",
            "Train Epoch: 63 [12800/40000 (32%)]\tLoss: 0.251806\n",
            "Train Epoch: 63 [19200/40000 (48%)]\tLoss: 0.620865\n",
            "Train Epoch: 63 [25600/40000 (64%)]\tLoss: 0.290877\n",
            "Train Epoch: 63 [32000/40000 (80%)]\tLoss: 0.281594\n",
            "Train Epoch: 63 [38400/40000 (96%)]\tLoss: 0.371408\n",
            "\n",
            "Average loss: 0.1631, Accuracy: 38068/40000 (95.170%)\n",
            "\n",
            "Train Epoch: 64 [6400/40000 (16%)]\tLoss: 0.203131\n",
            "Train Epoch: 64 [12800/40000 (32%)]\tLoss: 0.383504\n",
            "Train Epoch: 64 [19200/40000 (48%)]\tLoss: 0.525197\n",
            "Train Epoch: 64 [25600/40000 (64%)]\tLoss: 0.278802\n",
            "Train Epoch: 64 [32000/40000 (80%)]\tLoss: 0.243111\n",
            "Train Epoch: 64 [38400/40000 (96%)]\tLoss: 0.303446\n",
            "\n",
            "Average loss: 0.1826, Accuracy: 37847/40000 (94.618%)\n",
            "\n",
            "Train Epoch: 65 [6400/40000 (16%)]\tLoss: 0.490302\n",
            "Train Epoch: 65 [12800/40000 (32%)]\tLoss: 0.353534\n",
            "Train Epoch: 65 [19200/40000 (48%)]\tLoss: 0.089348\n",
            "Train Epoch: 65 [25600/40000 (64%)]\tLoss: 0.492706\n",
            "Train Epoch: 65 [32000/40000 (80%)]\tLoss: 0.451695\n",
            "Train Epoch: 65 [38400/40000 (96%)]\tLoss: 0.540580\n",
            "\n",
            "Average loss: 0.1565, Accuracy: 38006/40000 (95.015%)\n",
            "\n",
            "Train Epoch: 66 [6400/40000 (16%)]\tLoss: 0.368088\n",
            "Train Epoch: 66 [12800/40000 (32%)]\tLoss: 0.256922\n",
            "Train Epoch: 66 [19200/40000 (48%)]\tLoss: 0.628734\n",
            "Train Epoch: 66 [25600/40000 (64%)]\tLoss: 0.321912\n",
            "Train Epoch: 66 [32000/40000 (80%)]\tLoss: 0.596148\n",
            "Train Epoch: 66 [38400/40000 (96%)]\tLoss: 0.269528\n",
            "\n",
            "Average loss: 0.1612, Accuracy: 38068/40000 (95.170%)\n",
            "\n",
            "Train Epoch: 67 [6400/40000 (16%)]\tLoss: 0.392389\n",
            "Train Epoch: 67 [12800/40000 (32%)]\tLoss: 0.208868\n",
            "Train Epoch: 67 [19200/40000 (48%)]\tLoss: 0.121078\n",
            "Train Epoch: 67 [25600/40000 (64%)]\tLoss: 0.320622\n",
            "Train Epoch: 67 [32000/40000 (80%)]\tLoss: 0.242763\n",
            "Train Epoch: 67 [38400/40000 (96%)]\tLoss: 0.361891\n",
            "\n",
            "Average loss: 0.1478, Accuracy: 38159/40000 (95.397%)\n",
            "\n",
            "Train Epoch: 68 [6400/40000 (16%)]\tLoss: 0.277239\n",
            "Train Epoch: 68 [12800/40000 (32%)]\tLoss: 0.443929\n",
            "Train Epoch: 68 [19200/40000 (48%)]\tLoss: 0.364736\n",
            "Train Epoch: 68 [25600/40000 (64%)]\tLoss: 0.640420\n",
            "Train Epoch: 68 [32000/40000 (80%)]\tLoss: 0.178814\n",
            "Train Epoch: 68 [38400/40000 (96%)]\tLoss: 0.235873\n",
            "\n",
            "Average loss: 0.1596, Accuracy: 38161/40000 (95.403%)\n",
            "\n",
            "Train Epoch: 69 [6400/40000 (16%)]\tLoss: 0.527355\n",
            "Train Epoch: 69 [12800/40000 (32%)]\tLoss: 0.396710\n",
            "Train Epoch: 69 [19200/40000 (48%)]\tLoss: 0.281350\n",
            "Train Epoch: 69 [25600/40000 (64%)]\tLoss: 0.374233\n",
            "Train Epoch: 69 [32000/40000 (80%)]\tLoss: 0.442688\n",
            "Train Epoch: 69 [38400/40000 (96%)]\tLoss: 0.256608\n",
            "\n",
            "Average loss: 0.1511, Accuracy: 38100/40000 (95.250%)\n",
            "\n",
            "Train Epoch: 70 [6400/40000 (16%)]\tLoss: 0.635074\n",
            "Train Epoch: 70 [12800/40000 (32%)]\tLoss: 0.479099\n",
            "Train Epoch: 70 [19200/40000 (48%)]\tLoss: 0.239382\n",
            "Train Epoch: 70 [25600/40000 (64%)]\tLoss: 0.516968\n",
            "Train Epoch: 70 [32000/40000 (80%)]\tLoss: 0.430502\n",
            "Train Epoch: 70 [38400/40000 (96%)]\tLoss: 0.285743\n",
            "\n",
            "Average loss: 0.1450, Accuracy: 38134/40000 (95.335%)\n",
            "\n",
            "Train Epoch: 71 [6400/40000 (16%)]\tLoss: 0.197968\n",
            "Train Epoch: 71 [12800/40000 (32%)]\tLoss: 0.443531\n",
            "Train Epoch: 71 [19200/40000 (48%)]\tLoss: 0.386747\n",
            "Train Epoch: 71 [25600/40000 (64%)]\tLoss: 0.265593\n",
            "Train Epoch: 71 [32000/40000 (80%)]\tLoss: 0.253576\n",
            "Train Epoch: 71 [38400/40000 (96%)]\tLoss: 0.181678\n",
            "\n",
            "Average loss: 0.1483, Accuracy: 38181/40000 (95.453%)\n",
            "\n",
            "Train Epoch: 72 [6400/40000 (16%)]\tLoss: 0.163938\n",
            "Train Epoch: 72 [12800/40000 (32%)]\tLoss: 0.331507\n",
            "Train Epoch: 72 [19200/40000 (48%)]\tLoss: 0.171458\n",
            "Train Epoch: 72 [25600/40000 (64%)]\tLoss: 0.304263\n",
            "Train Epoch: 72 [32000/40000 (80%)]\tLoss: 0.158616\n",
            "Train Epoch: 72 [38400/40000 (96%)]\tLoss: 0.473338\n",
            "\n",
            "Average loss: 0.1516, Accuracy: 38202/40000 (95.505%)\n",
            "\n",
            "Train Epoch: 73 [6400/40000 (16%)]\tLoss: 0.233974\n",
            "Train Epoch: 73 [12800/40000 (32%)]\tLoss: 0.221778\n",
            "Train Epoch: 73 [19200/40000 (48%)]\tLoss: 0.387272\n",
            "Train Epoch: 73 [25600/40000 (64%)]\tLoss: 0.440848\n",
            "Train Epoch: 73 [32000/40000 (80%)]\tLoss: 0.622276\n",
            "Train Epoch: 73 [38400/40000 (96%)]\tLoss: 0.314991\n",
            "\n",
            "Average loss: 0.1671, Accuracy: 38053/40000 (95.132%)\n",
            "\n",
            "Train Epoch: 74 [6400/40000 (16%)]\tLoss: 0.427510\n",
            "Train Epoch: 74 [12800/40000 (32%)]\tLoss: 0.359365\n",
            "Train Epoch: 74 [19200/40000 (48%)]\tLoss: 0.246761\n",
            "Train Epoch: 74 [25600/40000 (64%)]\tLoss: 0.348168\n",
            "Train Epoch: 74 [32000/40000 (80%)]\tLoss: 0.187933\n",
            "Train Epoch: 74 [38400/40000 (96%)]\tLoss: 0.423082\n",
            "\n",
            "Average loss: 0.1528, Accuracy: 38090/40000 (95.225%)\n",
            "\n",
            "Train Epoch: 75 [6400/40000 (16%)]\tLoss: 0.389438\n",
            "Train Epoch: 75 [12800/40000 (32%)]\tLoss: 0.391422\n",
            "Train Epoch: 75 [19200/40000 (48%)]\tLoss: 0.187238\n",
            "Train Epoch: 75 [25600/40000 (64%)]\tLoss: 0.309725\n",
            "Train Epoch: 75 [32000/40000 (80%)]\tLoss: 0.327528\n",
            "Train Epoch: 75 [38400/40000 (96%)]\tLoss: 0.429062\n",
            "\n",
            "Average loss: 0.1402, Accuracy: 38306/40000 (95.765%)\n",
            "\n",
            "Train Epoch: 76 [6400/40000 (16%)]\tLoss: 0.402650\n",
            "Train Epoch: 76 [12800/40000 (32%)]\tLoss: 0.380326\n",
            "Train Epoch: 76 [19200/40000 (48%)]\tLoss: 0.263745\n",
            "Train Epoch: 76 [25600/40000 (64%)]\tLoss: 0.456392\n",
            "Train Epoch: 76 [32000/40000 (80%)]\tLoss: 0.161645\n",
            "Train Epoch: 76 [38400/40000 (96%)]\tLoss: 0.287211\n",
            "\n",
            "Average loss: 0.1342, Accuracy: 38386/40000 (95.965%)\n",
            "\n",
            "Train Epoch: 77 [6400/40000 (16%)]\tLoss: 0.294441\n",
            "Train Epoch: 77 [12800/40000 (32%)]\tLoss: 0.180093\n",
            "Train Epoch: 77 [19200/40000 (48%)]\tLoss: 0.600150\n",
            "Train Epoch: 77 [25600/40000 (64%)]\tLoss: 0.454519\n",
            "Train Epoch: 77 [32000/40000 (80%)]\tLoss: 0.197426\n",
            "Train Epoch: 77 [38400/40000 (96%)]\tLoss: 0.709279\n",
            "\n",
            "Average loss: 0.1939, Accuracy: 37964/40000 (94.910%)\n",
            "\n",
            "Train Epoch: 78 [6400/40000 (16%)]\tLoss: 0.162664\n",
            "Train Epoch: 78 [12800/40000 (32%)]\tLoss: 0.367629\n",
            "Train Epoch: 78 [19200/40000 (48%)]\tLoss: 0.113785\n",
            "Train Epoch: 78 [25600/40000 (64%)]\tLoss: 0.349942\n",
            "Train Epoch: 78 [32000/40000 (80%)]\tLoss: 0.463890\n",
            "Train Epoch: 78 [38400/40000 (96%)]\tLoss: 0.346571\n",
            "\n",
            "Average loss: 0.1393, Accuracy: 38308/40000 (95.770%)\n",
            "\n",
            "Train Epoch: 79 [6400/40000 (16%)]\tLoss: 0.226654\n",
            "Train Epoch: 79 [12800/40000 (32%)]\tLoss: 0.455396\n",
            "Train Epoch: 79 [19200/40000 (48%)]\tLoss: 0.244034\n",
            "Train Epoch: 79 [25600/40000 (64%)]\tLoss: 0.330376\n",
            "Train Epoch: 79 [32000/40000 (80%)]\tLoss: 0.172692\n",
            "Train Epoch: 79 [38400/40000 (96%)]\tLoss: 0.407314\n",
            "\n",
            "Average loss: 0.1457, Accuracy: 38338/40000 (95.845%)\n",
            "\n",
            "Train Epoch: 80 [6400/40000 (16%)]\tLoss: 0.510233\n",
            "Train Epoch: 80 [12800/40000 (32%)]\tLoss: 0.301902\n",
            "Train Epoch: 80 [19200/40000 (48%)]\tLoss: 0.506931\n",
            "Train Epoch: 80 [25600/40000 (64%)]\tLoss: 0.399503\n",
            "Train Epoch: 80 [32000/40000 (80%)]\tLoss: 0.269038\n",
            "Train Epoch: 80 [38400/40000 (96%)]\tLoss: 0.309877\n",
            "\n",
            "Average loss: 0.1448, Accuracy: 38156/40000 (95.390%)\n",
            "\n",
            "Train Epoch: 81 [6400/40000 (16%)]\tLoss: 0.437938\n",
            "Train Epoch: 81 [12800/40000 (32%)]\tLoss: 0.294925\n",
            "Train Epoch: 81 [19200/40000 (48%)]\tLoss: 0.495700\n",
            "Train Epoch: 81 [25600/40000 (64%)]\tLoss: 0.291977\n",
            "Train Epoch: 81 [32000/40000 (80%)]\tLoss: 0.325155\n",
            "Train Epoch: 81 [38400/40000 (96%)]\tLoss: 0.273700\n",
            "\n",
            "Average loss: 0.1427, Accuracy: 38216/40000 (95.540%)\n",
            "\n",
            "Train Epoch: 82 [6400/40000 (16%)]\tLoss: 0.352897\n",
            "Train Epoch: 82 [12800/40000 (32%)]\tLoss: 0.469245\n",
            "Train Epoch: 82 [19200/40000 (48%)]\tLoss: 0.547533\n",
            "Train Epoch: 82 [25600/40000 (64%)]\tLoss: 0.503953\n",
            "Train Epoch: 82 [32000/40000 (80%)]\tLoss: 0.254179\n",
            "Train Epoch: 82 [38400/40000 (96%)]\tLoss: 0.276939\n",
            "\n",
            "Average loss: 0.1638, Accuracy: 38307/40000 (95.767%)\n",
            "\n",
            "Train Epoch: 83 [6400/40000 (16%)]\tLoss: 0.336732\n",
            "Train Epoch: 83 [12800/40000 (32%)]\tLoss: 0.401948\n",
            "Train Epoch: 83 [19200/40000 (48%)]\tLoss: 0.194442\n",
            "Train Epoch: 83 [25600/40000 (64%)]\tLoss: 0.370390\n",
            "Train Epoch: 83 [32000/40000 (80%)]\tLoss: 0.151973\n",
            "Train Epoch: 83 [38400/40000 (96%)]\tLoss: 0.142127\n",
            "\n",
            "Average loss: 0.1565, Accuracy: 38225/40000 (95.562%)\n",
            "\n",
            "Train Epoch: 84 [6400/40000 (16%)]\tLoss: 0.212778\n",
            "Train Epoch: 84 [12800/40000 (32%)]\tLoss: 0.158102\n",
            "Train Epoch: 84 [19200/40000 (48%)]\tLoss: 0.341195\n",
            "Train Epoch: 84 [25600/40000 (64%)]\tLoss: 0.436899\n",
            "Train Epoch: 84 [32000/40000 (80%)]\tLoss: 0.352890\n",
            "Train Epoch: 84 [38400/40000 (96%)]\tLoss: 0.556448\n",
            "\n",
            "Average loss: 0.1323, Accuracy: 38340/40000 (95.850%)\n",
            "\n",
            "Train Epoch: 85 [6400/40000 (16%)]\tLoss: 0.401574\n",
            "Train Epoch: 85 [12800/40000 (32%)]\tLoss: 0.183779\n",
            "Train Epoch: 85 [19200/40000 (48%)]\tLoss: 0.303217\n",
            "Train Epoch: 85 [25600/40000 (64%)]\tLoss: 0.494962\n",
            "Train Epoch: 85 [32000/40000 (80%)]\tLoss: 0.379605\n",
            "Train Epoch: 85 [38400/40000 (96%)]\tLoss: 0.292539\n",
            "\n",
            "Average loss: 0.1911, Accuracy: 38206/40000 (95.515%)\n",
            "\n",
            "Train Epoch: 86 [6400/40000 (16%)]\tLoss: 0.264625\n",
            "Train Epoch: 86 [12800/40000 (32%)]\tLoss: 0.207631\n",
            "Train Epoch: 86 [19200/40000 (48%)]\tLoss: 0.313787\n",
            "Train Epoch: 86 [25600/40000 (64%)]\tLoss: 0.378771\n",
            "Train Epoch: 86 [32000/40000 (80%)]\tLoss: 0.360602\n",
            "Train Epoch: 86 [38400/40000 (96%)]\tLoss: 0.343532\n",
            "\n",
            "Average loss: 0.1239, Accuracy: 38486/40000 (96.215%)\n",
            "\n",
            "Train Epoch: 87 [6400/40000 (16%)]\tLoss: 0.153069\n",
            "Train Epoch: 87 [12800/40000 (32%)]\tLoss: 0.269428\n",
            "Train Epoch: 87 [19200/40000 (48%)]\tLoss: 0.368554\n",
            "Train Epoch: 87 [25600/40000 (64%)]\tLoss: 0.191901\n",
            "Train Epoch: 87 [32000/40000 (80%)]\tLoss: 0.258280\n",
            "Train Epoch: 87 [38400/40000 (96%)]\tLoss: 0.163375\n",
            "\n",
            "Average loss: 0.1302, Accuracy: 38453/40000 (96.132%)\n",
            "\n",
            "Train Epoch: 88 [6400/40000 (16%)]\tLoss: 0.384269\n",
            "Train Epoch: 88 [12800/40000 (32%)]\tLoss: 0.353919\n",
            "Train Epoch: 88 [19200/40000 (48%)]\tLoss: 0.204681\n",
            "Train Epoch: 88 [25600/40000 (64%)]\tLoss: 0.210287\n",
            "Train Epoch: 88 [32000/40000 (80%)]\tLoss: 0.363039\n",
            "Train Epoch: 88 [38400/40000 (96%)]\tLoss: 0.185553\n",
            "\n",
            "Average loss: 0.1257, Accuracy: 38406/40000 (96.015%)\n",
            "\n",
            "Train Epoch: 89 [6400/40000 (16%)]\tLoss: 0.623819\n",
            "Train Epoch: 89 [12800/40000 (32%)]\tLoss: 0.301708\n",
            "Train Epoch: 89 [19200/40000 (48%)]\tLoss: 0.213764\n",
            "Train Epoch: 89 [25600/40000 (64%)]\tLoss: 0.432270\n",
            "Train Epoch: 89 [32000/40000 (80%)]\tLoss: 0.258648\n",
            "Train Epoch: 89 [38400/40000 (96%)]\tLoss: 0.319670\n",
            "\n",
            "Average loss: 0.1329, Accuracy: 38425/40000 (96.062%)\n",
            "\n",
            "Train Epoch: 90 [6400/40000 (16%)]\tLoss: 0.453977\n",
            "Train Epoch: 90 [12800/40000 (32%)]\tLoss: 0.303230\n",
            "Train Epoch: 90 [19200/40000 (48%)]\tLoss: 0.284274\n",
            "Train Epoch: 90 [25600/40000 (64%)]\tLoss: 0.377870\n",
            "Train Epoch: 90 [32000/40000 (80%)]\tLoss: 0.150280\n",
            "Train Epoch: 90 [38400/40000 (96%)]\tLoss: 0.384318\n",
            "\n",
            "Average loss: 0.1284, Accuracy: 38451/40000 (96.127%)\n",
            "\n",
            "Train Epoch: 91 [6400/40000 (16%)]\tLoss: 0.296743\n",
            "Train Epoch: 91 [12800/40000 (32%)]\tLoss: 0.176065\n",
            "Train Epoch: 91 [19200/40000 (48%)]\tLoss: 0.447438\n",
            "Train Epoch: 91 [25600/40000 (64%)]\tLoss: 0.350531\n",
            "Train Epoch: 91 [32000/40000 (80%)]\tLoss: 0.339009\n",
            "Train Epoch: 91 [38400/40000 (96%)]\tLoss: 0.256314\n",
            "\n",
            "Average loss: 0.1359, Accuracy: 38474/40000 (96.185%)\n",
            "\n",
            "Train Epoch: 92 [6400/40000 (16%)]\tLoss: 0.275984\n",
            "Train Epoch: 92 [12800/40000 (32%)]\tLoss: 0.287642\n",
            "Train Epoch: 92 [19200/40000 (48%)]\tLoss: 0.224966\n",
            "Train Epoch: 92 [25600/40000 (64%)]\tLoss: 0.397033\n",
            "Train Epoch: 92 [32000/40000 (80%)]\tLoss: 0.367670\n",
            "Train Epoch: 92 [38400/40000 (96%)]\tLoss: 0.281738\n",
            "\n",
            "Average loss: 0.1175, Accuracy: 38521/40000 (96.302%)\n",
            "\n",
            "Train Epoch: 93 [6400/40000 (16%)]\tLoss: 0.244112\n",
            "Train Epoch: 93 [12800/40000 (32%)]\tLoss: 0.378017\n",
            "Train Epoch: 93 [19200/40000 (48%)]\tLoss: 0.228008\n",
            "Train Epoch: 93 [25600/40000 (64%)]\tLoss: 0.485047\n",
            "Train Epoch: 93 [32000/40000 (80%)]\tLoss: 0.296099\n",
            "Train Epoch: 93 [38400/40000 (96%)]\tLoss: 0.492761\n",
            "\n",
            "Average loss: 0.1574, Accuracy: 38351/40000 (95.877%)\n",
            "\n",
            "Train Epoch: 94 [6400/40000 (16%)]\tLoss: 0.180059\n",
            "Train Epoch: 94 [12800/40000 (32%)]\tLoss: 0.370332\n",
            "Train Epoch: 94 [19200/40000 (48%)]\tLoss: 0.551135\n",
            "Train Epoch: 94 [25600/40000 (64%)]\tLoss: 0.235840\n",
            "Train Epoch: 94 [32000/40000 (80%)]\tLoss: 0.286591\n",
            "Train Epoch: 94 [38400/40000 (96%)]\tLoss: 0.215736\n",
            "\n",
            "Average loss: 0.1184, Accuracy: 38478/40000 (96.195%)\n",
            "\n",
            "Train Epoch: 95 [6400/40000 (16%)]\tLoss: 0.172614\n",
            "Train Epoch: 95 [12800/40000 (32%)]\tLoss: 0.462852\n",
            "Train Epoch: 95 [19200/40000 (48%)]\tLoss: 0.436596\n",
            "Train Epoch: 95 [25600/40000 (64%)]\tLoss: 0.240311\n",
            "Train Epoch: 95 [32000/40000 (80%)]\tLoss: 0.137421\n",
            "Train Epoch: 95 [38400/40000 (96%)]\tLoss: 0.273229\n",
            "\n",
            "Average loss: 0.1213, Accuracy: 38578/40000 (96.445%)\n",
            "\n",
            "Train Epoch: 96 [6400/40000 (16%)]\tLoss: 0.276086\n",
            "Train Epoch: 96 [12800/40000 (32%)]\tLoss: 0.229172\n",
            "Train Epoch: 96 [19200/40000 (48%)]\tLoss: 0.460756\n",
            "Train Epoch: 96 [25600/40000 (64%)]\tLoss: 0.188435\n",
            "Train Epoch: 96 [32000/40000 (80%)]\tLoss: 0.286465\n",
            "Train Epoch: 96 [38400/40000 (96%)]\tLoss: 0.114807\n",
            "\n",
            "Average loss: 0.1252, Accuracy: 38537/40000 (96.343%)\n",
            "\n",
            "Train Epoch: 97 [6400/40000 (16%)]\tLoss: 0.394944\n",
            "Train Epoch: 97 [12800/40000 (32%)]\tLoss: 0.384164\n",
            "Train Epoch: 97 [19200/40000 (48%)]\tLoss: 0.269070\n",
            "Train Epoch: 97 [25600/40000 (64%)]\tLoss: 0.178157\n",
            "Train Epoch: 97 [32000/40000 (80%)]\tLoss: 0.318726\n",
            "Train Epoch: 97 [38400/40000 (96%)]\tLoss: 0.166939\n",
            "\n",
            "Average loss: 0.1385, Accuracy: 38429/40000 (96.073%)\n",
            "\n",
            "Train Epoch: 98 [6400/40000 (16%)]\tLoss: 0.235577\n",
            "Train Epoch: 98 [12800/40000 (32%)]\tLoss: 0.336589\n",
            "Train Epoch: 98 [19200/40000 (48%)]\tLoss: 0.234088\n",
            "Train Epoch: 98 [25600/40000 (64%)]\tLoss: 0.419696\n",
            "Train Epoch: 98 [32000/40000 (80%)]\tLoss: 0.154976\n",
            "Train Epoch: 98 [38400/40000 (96%)]\tLoss: 0.336590\n",
            "\n",
            "Average loss: 0.1190, Accuracy: 38488/40000 (96.220%)\n",
            "\n",
            "Train Epoch: 99 [6400/40000 (16%)]\tLoss: 0.450655\n",
            "Train Epoch: 99 [12800/40000 (32%)]\tLoss: 0.286068\n",
            "Train Epoch: 99 [19200/40000 (48%)]\tLoss: 0.307948\n",
            "Train Epoch: 99 [25600/40000 (64%)]\tLoss: 0.555241\n",
            "Train Epoch: 99 [32000/40000 (80%)]\tLoss: 0.523232\n",
            "Train Epoch: 99 [38400/40000 (96%)]\tLoss: 0.437491\n",
            "\n",
            "Average loss: 0.1176, Accuracy: 38523/40000 (96.308%)\n",
            "\n",
            "Train Epoch: 100 [6400/40000 (16%)]\tLoss: 0.329241\n",
            "Train Epoch: 100 [12800/40000 (32%)]\tLoss: 0.340986\n",
            "Train Epoch: 100 [19200/40000 (48%)]\tLoss: 0.436003\n",
            "Train Epoch: 100 [25600/40000 (64%)]\tLoss: 0.312962\n",
            "Train Epoch: 100 [32000/40000 (80%)]\tLoss: 0.379028\n",
            "Train Epoch: 100 [38400/40000 (96%)]\tLoss: 0.398839\n",
            "\n",
            "Average loss: 0.1252, Accuracy: 38486/40000 (96.215%)\n",
            "\n",
            "Train Epoch: 101 [6400/40000 (16%)]\tLoss: 0.191618\n",
            "Train Epoch: 101 [12800/40000 (32%)]\tLoss: 0.242342\n",
            "Train Epoch: 101 [19200/40000 (48%)]\tLoss: 0.456099\n",
            "Train Epoch: 101 [25600/40000 (64%)]\tLoss: 0.323448\n",
            "Train Epoch: 101 [32000/40000 (80%)]\tLoss: 0.327039\n",
            "Train Epoch: 101 [38400/40000 (96%)]\tLoss: 0.232638\n",
            "\n",
            "Average loss: 0.1214, Accuracy: 38494/40000 (96.235%)\n",
            "\n",
            "Train Epoch: 102 [6400/40000 (16%)]\tLoss: 0.133005\n",
            "Train Epoch: 102 [12800/40000 (32%)]\tLoss: 0.238665\n",
            "Train Epoch: 102 [19200/40000 (48%)]\tLoss: 0.389862\n",
            "Train Epoch: 102 [25600/40000 (64%)]\tLoss: 0.502988\n",
            "Train Epoch: 102 [32000/40000 (80%)]\tLoss: 0.227428\n",
            "Train Epoch: 102 [38400/40000 (96%)]\tLoss: 0.311966\n",
            "\n",
            "Average loss: 0.1250, Accuracy: 38424/40000 (96.060%)\n",
            "\n",
            "Train Epoch: 103 [6400/40000 (16%)]\tLoss: 0.244894\n",
            "Train Epoch: 103 [12800/40000 (32%)]\tLoss: 0.212853\n",
            "Train Epoch: 103 [19200/40000 (48%)]\tLoss: 0.203999\n",
            "Train Epoch: 103 [25600/40000 (64%)]\tLoss: 0.267515\n",
            "Train Epoch: 103 [32000/40000 (80%)]\tLoss: 0.350360\n",
            "Train Epoch: 103 [38400/40000 (96%)]\tLoss: 0.425033\n",
            "\n",
            "Average loss: 0.1189, Accuracy: 38494/40000 (96.235%)\n",
            "\n",
            "Train Epoch: 104 [6400/40000 (16%)]\tLoss: 0.219614\n",
            "Train Epoch: 104 [12800/40000 (32%)]\tLoss: 0.253295\n",
            "Train Epoch: 104 [19200/40000 (48%)]\tLoss: 0.130702\n",
            "Train Epoch: 104 [25600/40000 (64%)]\tLoss: 0.186644\n",
            "Train Epoch: 104 [32000/40000 (80%)]\tLoss: 0.458948\n",
            "Train Epoch: 104 [38400/40000 (96%)]\tLoss: 0.150724\n",
            "\n",
            "Average loss: 0.1265, Accuracy: 38582/40000 (96.455%)\n",
            "\n",
            "Train Epoch: 105 [6400/40000 (16%)]\tLoss: 0.232596\n",
            "Train Epoch: 105 [12800/40000 (32%)]\tLoss: 0.246441\n",
            "Train Epoch: 105 [19200/40000 (48%)]\tLoss: 0.329795\n",
            "Train Epoch: 105 [25600/40000 (64%)]\tLoss: 0.364051\n",
            "Train Epoch: 105 [32000/40000 (80%)]\tLoss: 0.361964\n",
            "Train Epoch: 105 [38400/40000 (96%)]\tLoss: 0.216705\n",
            "\n",
            "Average loss: 0.1217, Accuracy: 38616/40000 (96.540%)\n",
            "\n",
            "Train Epoch: 106 [6400/40000 (16%)]\tLoss: 0.234889\n",
            "Train Epoch: 106 [12800/40000 (32%)]\tLoss: 0.344005\n",
            "Train Epoch: 106 [19200/40000 (48%)]\tLoss: 0.353221\n",
            "Train Epoch: 106 [25600/40000 (64%)]\tLoss: 0.278580\n",
            "Train Epoch: 106 [32000/40000 (80%)]\tLoss: 0.245078\n",
            "Train Epoch: 106 [38400/40000 (96%)]\tLoss: 0.213986\n",
            "\n",
            "Average loss: 0.1225, Accuracy: 38555/40000 (96.388%)\n",
            "\n",
            "Train Epoch: 107 [6400/40000 (16%)]\tLoss: 0.210097\n",
            "Train Epoch: 107 [12800/40000 (32%)]\tLoss: 0.429545\n",
            "Train Epoch: 107 [19200/40000 (48%)]\tLoss: 0.138515\n",
            "Train Epoch: 107 [25600/40000 (64%)]\tLoss: 0.523721\n",
            "Train Epoch: 107 [32000/40000 (80%)]\tLoss: 0.143990\n",
            "Train Epoch: 107 [38400/40000 (96%)]\tLoss: 0.321058\n",
            "\n",
            "Average loss: 0.1117, Accuracy: 38610/40000 (96.525%)\n",
            "\n",
            "Train Epoch: 108 [6400/40000 (16%)]\tLoss: 0.473748\n",
            "Train Epoch: 108 [12800/40000 (32%)]\tLoss: 0.192023\n",
            "Train Epoch: 108 [19200/40000 (48%)]\tLoss: 0.470436\n",
            "Train Epoch: 108 [25600/40000 (64%)]\tLoss: 0.363432\n",
            "Train Epoch: 108 [32000/40000 (80%)]\tLoss: 0.471011\n",
            "Train Epoch: 108 [38400/40000 (96%)]\tLoss: 0.362989\n",
            "\n",
            "Average loss: 0.1113, Accuracy: 38668/40000 (96.670%)\n",
            "\n",
            "Train Epoch: 109 [6400/40000 (16%)]\tLoss: 0.338922\n",
            "Train Epoch: 109 [12800/40000 (32%)]\tLoss: 0.264012\n",
            "Train Epoch: 109 [19200/40000 (48%)]\tLoss: 0.187148\n",
            "Train Epoch: 109 [25600/40000 (64%)]\tLoss: 0.188635\n",
            "Train Epoch: 109 [32000/40000 (80%)]\tLoss: 0.096988\n",
            "Train Epoch: 109 [38400/40000 (96%)]\tLoss: 0.281553\n",
            "\n",
            "Average loss: 0.1078, Accuracy: 38725/40000 (96.812%)\n",
            "\n",
            "Train Epoch: 110 [6400/40000 (16%)]\tLoss: 0.203905\n",
            "Train Epoch: 110 [12800/40000 (32%)]\tLoss: 0.375292\n",
            "Train Epoch: 110 [19200/40000 (48%)]\tLoss: 0.216775\n",
            "Train Epoch: 110 [25600/40000 (64%)]\tLoss: 0.765636\n",
            "Train Epoch: 110 [32000/40000 (80%)]\tLoss: 0.478301\n",
            "Train Epoch: 110 [38400/40000 (96%)]\tLoss: 0.160279\n",
            "\n",
            "Average loss: 0.1257, Accuracy: 38507/40000 (96.267%)\n",
            "\n",
            "Train Epoch: 111 [6400/40000 (16%)]\tLoss: 0.511815\n",
            "Train Epoch: 111 [12800/40000 (32%)]\tLoss: 0.482075\n",
            "Train Epoch: 111 [19200/40000 (48%)]\tLoss: 0.366715\n",
            "Train Epoch: 111 [25600/40000 (64%)]\tLoss: 0.271743\n",
            "Train Epoch: 111 [32000/40000 (80%)]\tLoss: 0.478386\n",
            "Train Epoch: 111 [38400/40000 (96%)]\tLoss: 0.218101\n",
            "\n",
            "Average loss: 0.0997, Accuracy: 38712/40000 (96.780%)\n",
            "\n",
            "Train Epoch: 112 [6400/40000 (16%)]\tLoss: 0.279636\n",
            "Train Epoch: 112 [12800/40000 (32%)]\tLoss: 0.329787\n",
            "Train Epoch: 112 [19200/40000 (48%)]\tLoss: 0.445165\n",
            "Train Epoch: 112 [25600/40000 (64%)]\tLoss: 0.345344\n",
            "Train Epoch: 112 [32000/40000 (80%)]\tLoss: 0.334666\n",
            "Train Epoch: 112 [38400/40000 (96%)]\tLoss: 0.315130\n",
            "\n",
            "Average loss: 0.1208, Accuracy: 38528/40000 (96.320%)\n",
            "\n",
            "Train Epoch: 113 [6400/40000 (16%)]\tLoss: 0.229417\n",
            "Train Epoch: 113 [12800/40000 (32%)]\tLoss: 0.356265\n",
            "Train Epoch: 113 [19200/40000 (48%)]\tLoss: 0.136426\n",
            "Train Epoch: 113 [25600/40000 (64%)]\tLoss: 0.239663\n",
            "Train Epoch: 113 [32000/40000 (80%)]\tLoss: 0.269283\n",
            "Train Epoch: 113 [38400/40000 (96%)]\tLoss: 0.161130\n",
            "\n",
            "Average loss: 0.1059, Accuracy: 38642/40000 (96.605%)\n",
            "\n",
            "Train Epoch: 114 [6400/40000 (16%)]\tLoss: 0.438483\n",
            "Train Epoch: 114 [12800/40000 (32%)]\tLoss: 0.270233\n",
            "Train Epoch: 114 [19200/40000 (48%)]\tLoss: 0.231038\n",
            "Train Epoch: 114 [25600/40000 (64%)]\tLoss: 0.233037\n",
            "Train Epoch: 114 [32000/40000 (80%)]\tLoss: 0.357070\n",
            "Train Epoch: 114 [38400/40000 (96%)]\tLoss: 0.424272\n",
            "\n",
            "Average loss: 0.1199, Accuracy: 38609/40000 (96.522%)\n",
            "\n",
            "Train Epoch: 115 [6400/40000 (16%)]\tLoss: 0.225744\n",
            "Train Epoch: 115 [12800/40000 (32%)]\tLoss: 0.291220\n",
            "Train Epoch: 115 [19200/40000 (48%)]\tLoss: 0.333593\n",
            "Train Epoch: 115 [25600/40000 (64%)]\tLoss: 0.191081\n",
            "Train Epoch: 115 [32000/40000 (80%)]\tLoss: 0.398607\n",
            "Train Epoch: 115 [38400/40000 (96%)]\tLoss: 0.356504\n",
            "\n",
            "Average loss: 0.1092, Accuracy: 38693/40000 (96.733%)\n",
            "\n",
            "Train Epoch: 116 [6400/40000 (16%)]\tLoss: 0.251842\n",
            "Train Epoch: 116 [12800/40000 (32%)]\tLoss: 0.130705\n",
            "Train Epoch: 116 [19200/40000 (48%)]\tLoss: 0.630569\n",
            "Train Epoch: 116 [25600/40000 (64%)]\tLoss: 0.333026\n",
            "Train Epoch: 116 [32000/40000 (80%)]\tLoss: 0.528921\n",
            "Train Epoch: 116 [38400/40000 (96%)]\tLoss: 0.194615\n",
            "\n",
            "Average loss: 0.2523, Accuracy: 37753/40000 (94.382%)\n",
            "\n",
            "Train Epoch: 117 [6400/40000 (16%)]\tLoss: 0.121445\n",
            "Train Epoch: 117 [12800/40000 (32%)]\tLoss: 0.302244\n",
            "Train Epoch: 117 [19200/40000 (48%)]\tLoss: 0.238194\n",
            "Train Epoch: 117 [25600/40000 (64%)]\tLoss: 0.318974\n",
            "Train Epoch: 117 [32000/40000 (80%)]\tLoss: 0.298075\n",
            "Train Epoch: 117 [38400/40000 (96%)]\tLoss: 0.317822\n",
            "\n",
            "Average loss: 0.1052, Accuracy: 38710/40000 (96.775%)\n",
            "\n",
            "Train Epoch: 118 [6400/40000 (16%)]\tLoss: 0.261969\n",
            "Train Epoch: 118 [12800/40000 (32%)]\tLoss: 0.211623\n",
            "Train Epoch: 118 [19200/40000 (48%)]\tLoss: 0.284640\n",
            "Train Epoch: 118 [25600/40000 (64%)]\tLoss: 0.284561\n",
            "Train Epoch: 118 [32000/40000 (80%)]\tLoss: 0.325354\n",
            "Train Epoch: 118 [38400/40000 (96%)]\tLoss: 0.315630\n",
            "\n",
            "Average loss: 0.1070, Accuracy: 38816/40000 (97.040%)\n",
            "\n",
            "Train Epoch: 119 [6400/40000 (16%)]\tLoss: 0.272101\n",
            "Train Epoch: 119 [12800/40000 (32%)]\tLoss: 0.475906\n",
            "Train Epoch: 119 [19200/40000 (48%)]\tLoss: 0.361341\n",
            "Train Epoch: 119 [25600/40000 (64%)]\tLoss: 0.430858\n",
            "Train Epoch: 119 [32000/40000 (80%)]\tLoss: 0.307175\n",
            "Train Epoch: 119 [38400/40000 (96%)]\tLoss: 0.267378\n",
            "\n",
            "Average loss: 0.1290, Accuracy: 38710/40000 (96.775%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iDcyrWuaZHJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "q7pQsIqglkrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prediction(data_loader):\n",
        "    model.eval()\n",
        "    test_pred = torch.LongTensor()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            data = Variable(data, volatile=True)\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            pred = output.cpu().data.max(1, keepdim=True)[1]\n",
        "            test_pred = torch.cat((test_pred, pred), dim=0)\n",
        "        \n",
        "    return test_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBA5mxmwl3Xy",
        "colab_type": "code",
        "outputId": "35cf2921-ef2d-4408-fe3d-4741a3c03dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "test_pred = prediction(test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "N-Ht4ZfDmIas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame(np.c_[np.arange(0, len(X_test))[:,None], test_pred.numpy()], \n",
        "                      columns=['Id', 'Category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2wSpFYomb9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg2LqNQYmk2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}